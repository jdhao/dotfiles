## 2016 年 9 月
### 2016-09-01
早上开大组会，谭老师和其他组里的老师也去了，下午在修改上午的beamer 文件，查找了一下如何去修改beamer里面的table of contents的非当前section的opaqueness程度，最后终于解决了这个问题，下午吃完饭出去走了半个多小时，晚上看了一会儿beamer user guide。后面八点多刘瑞杰打电话，告诉我郑书怀跟他在一起吃饭，让我过去见一面，初中之后就没有见过了，好多年啊。
在那边聊了几个小时，大概十二点多回的宿舍，书怀在华锐风电工作，售后服务，刚去土耳其出差回北京。他给我和瑞杰一人一盒带回来的土耳其糖，又给我们每人一个土耳其里拉硬币作为纪念。

### 2016-09-02
今天在写论文，写了一个白天，只写了一点点，从最简单的数据库描述写起来。下午五点多，和实验室同一届的同学一起去吃饭，巴依老爷，新疆口味，以前去吃过一次，感觉并不是很好吃，我不喜欢，肉大多没有什么味道。晚上吃完饭，去找吉吉了，和他在北航逛了逛，聊了一会天，然后后面又回实验室了。

### 2016-09-04
昨天上午来实验室，稍微看了一会东西，继续写论文，然后九点半左右出发，十一点十五的城际，大约十二点到天津，坐了半个小时的公交到了鹤鸣租住的地方。中午鹤鸣和我一起，做了一顿焖面，休息了一下，下午的时候去超市买了点东西，晚上做了个凉拌的胡萝卜芹菜花生，喝了点汤。鹤鸣后面又准备了一下肉夹馍的肉，煮了一下。
早上去鹤鸣医院取了个苦荞茶，去菜市场买了个饼子，又买了点豆腐脑，回来用饼子做了一下肉夹馍。然后帮鹤鸣把衣服，被罩洗了一下，中午鹤鸣做的哨子面，挺好吃的。下午睡了一会儿，四点多从鹤鸣住的地方出发，五点二十三的城际回北京，到北京大概六点左右。
去找吉吉了，先去吃了个饭，我吃的面条，请吉吉吃了个紫菜包饭，但是感觉味道一般。吃完饭我们先去北京联合大学文理学院走了一下，没什么逛的，很小的学校。后面一起去北影里面走了一下，北影也是刚开学，还看到了一些欢迎2016级新生的字样，后面和吉吉在讨论朝鲜战争的一些问题，发现他连最基本的历史事实都不太清楚，一味相信历史书上讲的那些东西。后面也聊的不是很愉快，他总是大声说话，试图压制住我。
晚上十点多坐公交回实验室，在实验室看了一会东西，大约十一点二十回的宿舍。

### 2016-09-05
早上先又看了一遍cvpr的author guideline，然后在看一个cvpr的paper template里面提到的关于书写equation的短文。

#### 书写equation的一些rule
* rule 1(Fisher's rule)： 每一个公式都应该给出编号，以方便读者对公式的引用
* rule 2(Good Samaritan rule)： 引用每一个公式的时候，不仅引用公式的number，同时要配上一段话，简要说明引用的东西。仔细看了以后，觉得这个rule并不太适用于cvpr这种应用文章很多的会议，cvpr的论文大多从效果出发，公式论证之类的东西并不多，所以并不是太需要这里面说的东西。
* rule 3(Math is prose rule)： 每一个display equation应该用标点符号结束。公式也是文章的一部分，应该有标点符号在公式后面，增加文章的可理解性。

下午在写论文，吃完饭出去走了一圈，回来继续写论文，后面九点多，想研究怎么在手机上使用gfw，研究了半天，下载了好几个应用，最后发现这个应用不是很好用。晚上回去早点。

### 2016-09-06
我们应该如何看论文。
上周开了大组会，第一个讲的人是崔强，谭老师问他看了文章有什么收获，得到了什么启示，为什么要选择他讲的那三篇文章。这样的问题并不好回答，如果我是第一个讲的，我都不知道该如何回答这几个问题，可能也只是泛泛而谈，说一些空话。
我后面也经常想起这句，有什么收获？虽然是简单的一句话，却给人很多的压力。有时候我们看文章总容易陷入盲目，忘记自己的目的，单纯追求看了多少文章，这样并没有太多意义。
应该时常想想自己为什么要看某篇文章，获得了什么，文章已经很好了吗？有没有可能的缺陷，这样才能提高。

（2016年9月30日更新）我看论文，现在还是从头看到尾，缺乏重点（虽然并不是毫无重点），只是抱着学习态度一样，并没有太多思考作者的解决方法可能有什么问题，当然这也跟没有跑代码有关，只是看论文，有时候你会觉得一切很美好。

【论文阅读】learning fine-grained image similarity with deep ranking
这篇文章是比较早的使用triplet network的文章，作者的创新主要在如何获取训练数据（用所谓的golden feature 来选出一些训练图片），如何从训练数据中找出合适的可用于训练的triplet，提出了一种online triplet选取策略，最后最重要的贡献在于使用triplet network直接用来训练一个end-to-end的网络，一步到位实现特征提取与ranking model的训练。

今天上午和下午在看上面的那篇论文，晚上在写论文。

### 2016-09-07
中国高铁走出去面临的问题，资金（修建高铁需要资金极高），国家安全考虑（军事安全，基础设施不愿被国外公司控制等），国外与国内环境的不同（征地，人工成本等）

上午在开小组会，叶奎和徐金东讲，叶奎讲了他最近做的一些东西，实验以及读论文等，董老师跟他说要开始专心搞自己的科研了，不要花费太多时间搞这些跟自己方向关系不大的东西，我认为老师说的太过于绝对，并不具有太大参考价值，我的感觉，现在深度学习这些东西，对编程的要求还是比较高的，如果你编程不行，很可能会拖你的后腿，导致你想做的东西也做不了，所以科研并不仅仅是想出一个idea。我觉得论文与编程都很重要，同时这两者的时间分配也需要注意，编程比较重要，但是不能把大部分时间都投入到编程，还是尽量以任务导向，不能想着把编程都搞好了，什么知识点都掌握了采取做实验，这个是不现实的，会花费太多时间。当你有空时候，再系统基础地去学习编程方面的知识细节。
下午在想论文的纲要，也把论文稍微修改了一下，现在还有几部分没写，后面看了一会端传媒的新闻，晚上吃饭去吃的庆丰包子。
晚上的时间都在看跟中国高铁相关的东西，国内搞这些东西，给人的感觉就是最长，最大，最快等等数量词，不论是官方还是民间都对这些东西津津乐道，以此来显示中国的高铁技术已经怎么怎么样了，总让人觉得有种暴发户的味道。每当媒体报道这些内容时候，都给人一种很欢欣鼓舞的样子，但是这些东西真的是对中国有利的吗，需不需要修建这么多的高铁线路，能否盈利？

### 2016-09-08
上午在想写给老师的论文纲要，下午在写论文，四点多开始开会，吃完晚饭出去走了一圈，今天走的有点远，跑到北航那边，从大运村西路到了北四环，然后又回到自动化所。在中关村西路，靠近北航那里，有一个菜市场，还有许多卖日常生活用品的，比较杂乱，那里的空气也不好，到处都能闻到烧烤以及一种臭臭的味道，这也算是中国底层的生活真实写照吧，真实的folding beijing。
晚上回来，看了一下天）×安#&门有关的事情。

### 2016-09-09
#### PPP reading: 什么是「多态」？
>Polymorphism is the Greek for "many shapes", refering to the many different types you can manipulate through a common interface.

今天继续写论文，下午还写了一会儿代码，想看看把不同的layer的信息结合起来，会不会提升效果，发现果然有一些提升，特别是把效果最好的层进行结合（2016九月三十更新，但是这样使用的特征维数就很高了，不是低维度的特征了）。 晚上去打羽毛球，今天去的人少，单打，比较累，跑不动。

### 2016-09-10
上午在宿舍睡觉，下午来实验室，玩了两个小时三国杀，后面在继续做一些小实验，六点多回宿舍，吃了点葡萄，玩了一会三国杀，又看了一会神街访。大约八点来的实验室。
晚上发现以前做的实验，有几个结果有问题，把这几个又重新求了一下特征，然后计算了一下最新的结果。然后求了Paris 数据库的多尺度的特征，打算进行pca实验看看结果。

### 2016-09-11
上午在宿舍休息，下午和吉吉去吃了个饭，请他在站点比萨中关村店吃饭。吃完饭一起去中关村那边走了一下，后面四点多快下雨时候分别，我坐车回公寓，在宿舍玩了一会三国杀，七点左右到实验室。
发现鹤鸣给我发消息说电脑上不了中国知网，帮她把这个问题解决了，到实验室大概八点多。然后开始做multiscale加上pca的实验，首先要提取paris数据库的fc6以及conv54特征，结果fc6特征提取的程序一直出错，后面基本都在解决这个问题了，最后发现可能是各个scale的slice的设置有问题，以致图像尺寸太小的时候出现问题。解决这个问题一直到晚上十二点多。

### 2016-09-12
上午在实验室做实验，做的是oxford数据库的特征，在本数据求取pca矩阵以及在paris数据库求取pca矩阵，然后对特征进行pca，whitening，发现在paris数据库求pca矩阵，会进一步提升性能，无论是对于full query，还是crop query。
下午来实验室继续做吧fc6的特征和conv54特征结合起来的实验，性能进一步提升，最终在oxford5k的mAP能够达到74.6(full query), 比当前看到的其他方法的结果要高(20160930更新，事后想想，这并没有用，因为特征维度比较高，用处不大)。
下午会宿舍吃了点东西，玩了一小会三国杀，休息了几分钟，七点半左右来的实验室。对于到底在哪个数据上做实验还是有点犹豫，查了一下holiday数据库以及ukb数据库的一些资料，然后把holiday的图片都调整为直立的方向，压缩以后，重新往数据库上传了一份（2016年9月30更新，最后由于holiday图像太大，无法进行free方式的处理，决定放弃holiday，使用ukb)。
今天在写论文上没进展多少。

### 2016-09-13
人的认识一直在进步，在改进，当我刚开始做oxford building数据库的实验时候，只想着看看效果，因此许多想法并没有很成熟，只是在当时的条件下去思考问题，譬如当时只是看到别的论文里说最后一层卷积层做检索的效果比较好，所以就用了最后一层卷积层conv54，因此得到的特征以及结果命名也没有加上conv54，等到后面用到更多的层了，才发现必须加上层的名字，否则容易混淆；再比如前面只是用的l2归一化，后面又实验了L1归一化，因此特征以及文件的命名都发生了一些变化。
还有一些方法上的不成熟的地方，刚开始把跟网络有关的方法都放到了一个文件里，导致后面要求取不同的特征这些代码被复制到不同文件里面，有很多重复。

感觉还要好几个实验要做，顿时人就不好了，可是这些实验真的是很难得吗，并不见得，只是心里有点说不清道不明的东西罢了，有时候想到有这么多的东西要做，有点犹豫有点害怕，觉得自己应付不了，这个实验肯定会耗费大量时间，真的去做的话，发现并没有消耗很多的时间。

今天又写了一点程序，下午在写论文(纠结如何表示实验结果，是用图片呢，还是用表格，想了半天，决定还是用表格，然后又在使用png还是eps格式的问题上研究了半天，发现还是eps格式比较好，不会因为放大模糊，然后对于使用多大的caption又研究了一番，发现cvpr上论文的caption都比正文里面的字体要小一些)。晚上吃完饭，和鹤鸣聊了一会，她说我边走边吃东西的习惯不好，要我改正，我认为没有关系，所以不想有所变化，说了半天，最后同意改正。后面回来在搞holiday 数据库的整理，把query和ground truth信息写程序整理了一下(本来让叶奎帮忙整理了一下，发现还是不太想麻烦他，所以就自己又搞了一下)；然后打算进行paris105k的实验，在flickr数据上鼓捣了半天，原来下载的那些flikcr的图片由于数量比较大，被分成了40个rar压缩文件，但是这些rar文件不知什么时候已经被解压开了，因此现在是解压开的图片和那些压缩文件同在一个目录，而且这个根目录下面还有第40个压缩文件单独解压开的一个目录，非常凌乱。我想把这些解压后的图片移动到另外一个目录，结果发现单纯使用系统提供的mv命令不能移动如此大量的图片(大约10万张)，后面又查了一下在Linux系统中如何从一个目录移动大量文件到另外一个目录，解决了这个问题。但是我不确定原来解压开的那些图片数量是否完整，所以我又重新把那40rar文件解压了，最后比较了一下重新解压后的图片数量与原来移动到另外一个目录的图片数量，发现这两个是一样的，这才最终放心。

### 2016-09-14
今天看了一会别的论文，发现Tolias iclr2016那篇论文给出的方法比较，貌似有的方法放的位置不太对，譬如aggregating deep convolutional features 那篇，有一个oxford数据库的结果是使用full query跑出来的，但是作者给的时候貌似是按照cropped query给出的，因此在文中提到他用到的oxford 数据库query 图片都是用bounding box的。。
下午还跑了一下conv54-3scale-overlap这种特征在paris数据库以及oxford数据上做pca的结果，发现好像要比4 scale的要差一些。
把下午跑的conv54_3scale_overlap这种情况在paris以及self上面的结果画了几个图，分析了一下，发现3scale的结果还是要差于4scale的结果的，于是决定先跑4scale的结果。
晚上写了一下提取holiday特征与flickr特征的代码，提取4scale的特征，结果holiday的图像尺寸太大，于是对图像最大尺寸缩放到了1024才可以进行实验，这个好像也不算是free了。。不过我觉得会比resize成方块的要好一些，晚上快走的时候，又运行了一下flickr100k图像的特征提取。

### 2016-09-15
#### 有感
教育改变命运，这句话对吗？我想大概是对的

下午两点多到实验室，结果发现昨天提取flickr100k图像的程序运行到7万多的时候出错了，日了狗，最后发现是因为有一张图片被corrupt了，所以读取的时候有问题，先找了这张图片，最后才确定这张图片是被污染了，后面再查如何确定一张图片是否被污染了，师兄说可以通过捕获异常的方式来发现有问题的图片。刚才使用的是PIL里面Image模块的show方法来捕获异常，但是对于正常的图片，就会显示出来，并且这个窗口无法自动关闭，显然是不行的，最后把几种打开图像的方法都试了一下，发现skimage里面的io模块可以不用直接显示图片就可以捕获异常，最后决定使用这种方法。
把flickr100k的图片过了一遍，发现就昨天那一张有问题，其他都没有问题，我也是醉了。后面吃饭时候，和程文龙，张宇琪一起去中关村那边，本来想去南京大排档，结果人太多了，作罢，去了北京大学中关新园那边的餐厅。回来实验室，把flickr的数据库求取特征的程序又写了一下，本来打算是使用线性的求特征的方式，只用了一块GPU，后面决定采用并行的方式，把所有图片分成五份，同时开始计算特征，然后最后合并，能加快速度。
晚上和鹤鸣聊了一会。

### 2016-09-16
上午来实验室，看了一个纪录片的上部，Afganistan, the great game，中午回宿舍吃了个饭，睡了一觉，下午大约四点钟来宿舍，来的有点晚了，感觉没有精神，困的不行。
下午来把昨天做的检查损坏图片的的东西总结了一下，看了一下linux里面find命令的使用，复习一下。

#### 追随者or开拓者
我们为什么很难发很好的论文呢？敢为人先的勇气，敏锐与洞察力，编程，多方面的因素。

晚饭吃了几个包子，在宿舍呆了一会。晚上在写论文，写到了九点多，快十点，和鹤鸣聊了一会，讨论了一下中医如何定位的问题，争论了半天。。一说到中医，就容易起分歧，我说中医里面有很多骗人的东西，她说那些不是中医，后面又举了穿山甲被中医用药的例子，我觉得不科学，没什么道理，她觉得有道理，我也说服不了她，她很固执，一直坚持认为这是老祖宗传下来的，经过经验挑选的，并且是纯天然的，所以就是好的，对于这样的逻辑，唉。

### 2016-09-17
上午在宿舍休息，本来打算来实验室的，结果太困了，于是就在宿舍休息了，大概十一点左右起床的。刘瑞杰说要请我吃饭，起床洗漱了一下，就过去清华那边了，他在那边自习。和他一起去日昌，人有点多，排了一会号，两个人点的东西有点多，到后面没吃完，他不吃肉，我点了个排骨，结果感觉也不好吃，就没吃多少，两个人最后大概190，感觉贵了。
吃完饭，一起去他自习的地方看了一会书，他在复习保荐人资格考试的内容，打算明年考这个，他还买了一本俄罗斯人编的《微积分学教程》，我拿着那本书看了一会，这本书的内容很细，光有理数的性质等就讲了好几页，而且很严谨，各种定理都有证明过程。
晚上在写论文。

### 2016-09-18
假期结束，开始新的工作，今天写了比较多的字数，昨天又做了一些实验，发现sum_l1的方式在single_scale的时候效果比max_l2还要好，所以又提取了sum_l1的多尺度的特征，发现多尺度的特征效果还不如单尺度的，所以最终决定还是使用max_l2处理的特征。晚上回宿舍吃了点东西，看了一集《晓松奇谈》，讲加拿大的温哥华市，晚上七点半来实验室。继续写论文，大约十一点回宿舍。

### 2016-09-19
写论文，修改论文。下午会宿舍吃晚饭，包子加泡面，看了一集《晓松奇谈》，七点二十到实验室。晚上继续写论文，Introduction 和related work还没有写，实验部分还有一些没有写完。

### 2016-09-20
明天开小组会，我要讲报告，所以今天看看论文，下午来实验室，看到了一个python tips and tricks，学习了一下，不过大部分我都知道了。。

刚才查了一下credit-to-GDP gap，衡量的是credit-to-GDP的ratio与long-term trend直接的差值，中国的这个数值已经到了30.1(参见这里)，比较健康的数值是2%一下，可见中国的信贷已经到了什么规模，如果这个数值过高，一般会预示着银行方面的危机，不知道中国未来如何？
具体的定义可以参见这里， 另外一篇对这个credit-to-GDP gap讨论的博客可以参见这里

今天主要是看了一篇论文《deep metric learning  via lifted structured imbedding》，下午没回宿舍吃晚饭，但是晚饭后出去走了一会儿，然后回来实验室做了一下PPT。晚上大约八点，老牛打电话过来，和他聊了一会，他在中南的研究生生涯刚开始，

**[论文阅读]deep metric learning via lifted structured imbedding**  
这篇文章提出了一个一种新的loss来进行fine grained recognition和retrieval，以前检索很多方法用的是siamese的结构，采用contrastive loss来优化，训练的时候数据是成对输入，并且附带标签，表示两个图片是同一类还是不是同一类。
后面的triplet 网络用到的是triplet loss，训练的时候，用到的样本是三元组，一个anchor图片，还有一个与anchor同一类的positive图片，一个和anchor 不是同一类的negative图片，然后triplet loss的cost function优化的目标就是anchor和positive的距离加上一个阈值alpha要小于anchor和negative 图像之间的距离。
这篇文章用到了新的cost function，形式如下：



优化的时候，实际上是优化另外一个方程，



作者的实验是在三个数据库上进行的，都取得了很好的效果。

作者在论文中用到的approximation的公式，也就是把不可导的max方程转换为可导的方程的过程，我去网上专门查了一下，是有这个公式的，具体如下


并且，大数的soft max逼近效果更好一些，譬如g(9, 10) = 10.313, g(90, 100) = 100.000，所以如果想要取得更精确的逼近效果，可以先把两个数乘以一个整数倍的因子，然后结果再缩放相同倍数，用公式来表示的话，可以写成：


更详细的内容，可以参考[这篇博客](https://www.johndcook.com/blog/2010/01/13/soft-maximum/)。

### 2016-09-21
上午在开DIF小组的会，下午来实验室去上了一节「最优化理论及应用」的博士课。

#### 两个fine-grained 关于分类识别检索的数据库。
第一个是CUB-2011， 是关于鸟的一个数据库，200类，一万多张图片，具体可以参见官方网站
第二个是Car196，是关于车的一个书库，196类，也是一万多张图片，具体参考官方网站

晚上又看了一会儿昨天的那篇论文，搞清楚了里面的公式近似的原理。
max(x, y)可以近似为log(exp(x) + exp(y))
具体可以参考这篇博文，http://www.johndcook.com/blog/2010/01/13/soft-maximum/

### 2016-09-22
上午去体检了，大概十点左右体检完毕的，回到实验室，继续写我的论文，下午继续，后面开大组会就参加大组会了。晚饭时间去北航那边吃的，吃的是生煎，和吉吉一起吃的，感觉味道还不错。吃完饭聊了一会，然后回所里大概八点钟。后面回来写论文，好像也没有写了多少。

### 2016-09-23
今天继续写论文，上午看了一会儿tikz画图的东西，感觉太多了，看了一两个教程就没看了。今天发现以前的实现提取conv54_4scale_version2特征的代码有一处错误（scale4的slice由于粗心，有一个slice写错了，本来应该是六分之几，结果写成了四分之几，2016年9月30日更新），导致跟version2有关的结果都有问题，需要重新求特征来计算，并且经过重新计算以后，试验结果要好于version1的结果，这特么就尴尬了，我需要重新求很多特征，我的内心是崩溃的。下午在写论文，又推进了一些。晚上去打球了。

### 2016-09-24
上午在宿舍休息，中午吃完饭到实验室，大概十二点半，把上次看得关于Afganistan的纪录片下部看完了，阿富汗从十八世纪到21世纪受到三个大国的侵略却始终不能被征服，但是战争也给阿富汗人造成了很多的伤亡与痛苦，同时近些年的战争也造成了恐怖主义伊斯兰极端组织在阿富汗的崛起，这也是和平的一大威胁。后面开始写论文，发现了一个如何提问的博客，把这个博文看了一遍，博文很长，花费了不少的时间。
一个比较长的关于如何提问的博客。
http://www.catb.org/esr/faqs/smart-questions.html
下午回宿舍那边吃了个饭，然后在宿舍洗了个衣服，大概七点多到实验室。继续写论文。又向前推进了一点点。

### 2016-09-25
上午在宿舍休息，下午大约三点到实验室，继续写论文。晚上大约七点出去吃饭，吃的猫婆小面，味道还可以，大约八点多一些回实验室。回来以后，查了一下北京和天津好吃的面条，记录了一下，有空的时候打算去吃一下。这个做完以后，又看了一下蛮族勇士的微博，关于北京，上海，深圳的经济分析，以及他写的武汉，合肥，常州经济分析。后面又到天涯上，把他最近写的关于历朝历代的改革者的文章看了一下。到了十点多，大约花费了两个多小时的时间。

### 2016-09-26
今天上午去参加了一个模式识别实验室的迎新会，大约十一点十分结束，然后中午和杜言劼一起吃饭，聊了一会。吃完饭回实验室，感觉吃太多了，撑的难受，出去走了一圈，大约三点半回到实验室。
看了一会买的MIT的微积分教材，晚上来实验室做实验，打算把除了Oxford之外的实验都做一下，在Paris上做实验，发现在Oxford上pca以后效果还是可以的。后面又写了一会儿程序，处理ukb的数据。

### 2016-09-27
继续写论文。今天做做实验，把在UKB数据集实验的代码写了一下，刚开始代码没写对，结果就很差，我以为我方法有问题，吓了一跳，后面发现是代码问题，就纠正一下，发现结果还是不错的。Paris数据集还有Oxford105k这些数据库上的实验都做了一下。 同时还做了在UKB 上面pca的实验，以及Paris数据库PCA的实验，发现Paris数据库如果使用自己的上面求取的PCA矩阵结果比较差劲，使用Paris数据库上面求取的PCA矩阵，效果会比较好，媲美最好的state-of-the-art. UKB上面PCA结果没有太大提升。

### 2016-09-28
上午在做论文的最后一部分实验比较的表格，下午来继续做，没做完，然后下午上了一节最优化理论与应用的课程。晚上吃完饭出去走了一会儿，第一次骑了一下那个摩拜单车，发现骑起来并不是很沉，挺好骑的，骑了大概有三十分钟，然后不想再多骑了就到路边可以停车的位置，把车子锁上，大概骑了5公里左右。总共大概用了一个小时，然后回到实验室继续写论文，把论文的表格做好了，和其他实验的比较内容也写了一下。

### 2016-09-29
写论文，自己的实验和其他论文结果的比较，文字部分，顺便又修改了一下其他我觉得不太通顺的地方。下午看了一下如何写论文的related work，想了想如何写related work，然后开了一个大组会，开完大组会和沈艳宇聊了一会儿。
吃完饭，出去走了一圈，大概用时三十分钟，六点半左右回到实验室，看了一会儿微博。然后上了一会网，在豆瓣上逛了一下，看了看《一课经济学》的书评，然后又看了看《东藏记》的书评，看到了一个列的书单，发现一本书《计算中的上帝》，就搜索了一下这本书，大概用时一个小时。后面继续写论文

### 2016-09-30
上午在想写related work，然后开始动笔，下午又写了一部分，大约写到三点四十，然后看了一会其他的东西， 买了一本《雷震传》，看了一下CNN写的采访王健林的稿件，王健林称中国房地产泡沫是有史以来最大的(the greatest bubble)，后面又看了一会儿华盛顿邮报和经济学人(讲的是关于中国的贫穷省份与富裕省份差距的问题)。
晚上去打球了。

## 2016 年 10 月
### 2016-10-01
昨天又做了一些各层score融合的实验，不过没有做完，可以称做layer ensemble， 后面一直在写论文，把related work和introduction快写完了。

### 2016-10-02
早上起来来实验室，把论文的introduction部分剩下的写完了，十一点从所里出发去北京南站，坐十二点五十的火车去天津，假期人比较多，刚出了地铁站，差点都找不到东南西北了。到了天津，然后打车去找鹤鸣，她们老师那天正好请她们几个同学吃饭，到了那个饭店，等了一会儿，他们才吃完饭。
还被鹤鸣训了一顿，嫌我和她老师打招呼的时候不热情，后面她陪我吃了个饭，顺便给自行车补了一下胎。 晚上时候一起去买了点菜，做了一个西红柿鸡蛋面。

### 2016-10-05
三号早上吃了早点，洗了洗衣服，然后中午十一点的时候和鹤鸣一起出发去「南京大牌档」吃饭，路上有点堵车，坐公交坐了大概有一个小时，到了地方，人比较多，排队了比较长的时间才轮到我们。
那里的菜分量都不大，而且不贵，我们多点了几个菜尝尝鲜，味道挺好。
四号早上睡了个懒觉，鹤鸣出去帮忙买的早点，老豆腐和煎饼果子，中午我们一起做的烧茄子，虽然是第一次做，但是做的还不错。下午帮鹤鸣炸了一下薯条。我们一起去沃尔玛买了点东西，晚上我们拌了点黄瓜吃。 鹤鸣又煮了点肉和鸡蛋，准备第二天做肉夹馍。
五号早上鹤鸣出去买的豆腐脑还有饼子，做的肉夹馍，味道很不错，中午我们一起吃的豆角焖面。该走了，感觉有点舍不得，所以磨蹭了一会儿，打算和鹤鸣一起去看一场电影，结果火车票没有改签成(网上的改签只支持开车前30分钟，30分钟以内不支持改签)。赶紧叫了个滴滴过去火车站改签，火急火燎，害怕误了看电影的时间，改签到了晚上八点半。然后改进奔着电影院跑，最后跑到电影院，坐在座位上，已经满头大汗，衬衫都湿了，没有迟到。
看完电影，五点半，还有三个小时开车，于是和鹤鸣一起去前面收藏的一个日式面馆吃饭，在南京路那边，结果到了以后发现没有营业。于是原路返回，在滨江道步行街看了看外套，然后就在街上买了点小吃。后面坐车回到北京，去实验室坐了一会儿才回宿舍。

### 2016-10-06
上午在实验室休息，中午吉吉叫我一起去吃面，我上次跟他说过一个陕西省驻京办的地方，然后我们就去那了，点了一个小份肉夹馍以及小份的羊肉泡，吉吉点了一个小份油泼面，结果肉夹馍和羊肉泡特别坑爹，分量特别小。吃完饭，吉吉有事，于是一起坐地铁回去了，我回宿舍玩了两个小时的三国杀，又休息了一下，晚上八点多到实验室，写了一会儿代码，把layer fusion的实验代码写完了。

### 2016-10-07
上午九点多来实验室，看了一会儿前面买的那本《calculus with analytical geometry》，下午一点多回宿舍，看了一会儿手机，睡了一觉，到了晚上七点多，买了点东西回实验室，把UKB上面的实验也做了一下。后面写了一会儿论文，把论文又修修补补了一番。

### 2016-10-08
今天又把论文从头到尾看了一下，修改一些明显的错误，重新画了一些图，但是还有一些深层的问题还没有解决，譬如论文里面动词的时态问题，我还没有搞太清楚规则，不知道什么时候用什么。
下午把论文发给董老师了。下午吃完饭，六点半出去遛了一圈，和鹤鸣聊了一会儿，大约七点半多一些回到实验室。这几天有两条裤子因为爬梯子上床结果屁股被撑破，快没有裤子穿了，鹤鸣帮我在网上看了看，推荐了几个，我回到实验室也挑选了一下，买了两件，一条裤子，一件衬衫。买完这些东西，大概已经到了晚上八点四十多。后面又查了一下怎么把图片并排摆放的问题，找出的答案都是针对一栏的文章，对于分开两栏的文章，那些方法并不管用。
后面看微博发现了一条关于谢百三的帖子，说的是他一些枉为师表的例子，我把这个发给了刘瑞杰，因为我看到他前几天还发朋友圈纪念这个人了。看来对于自己不了解的人或者事，最好还是不要随意表态，不要轻信，以免自己被骗，可以看看多方面的评价，不能偏信一方面的结论。我还向他推荐了一下摩拜单车，后面又在网上看了看关于ofo和摩拜，以及滴滴公司投资ofo的一些报道。

### 2016-10-09
今天主要查了一下昨天没有解决好的问题，就是如何在两栏文章的其中一栏并排摆放图片，后面查了很多资料，都没有找到，所以在stackexchange上面问了一下，下午来就得到了回答，原来是我使用的宽度有问题，应该把\textwidth换成\columnwidth，然后就不会有问题了。
后面查了一下lipsum这库的使用方法，以及\textwidth, \linewidth， \columnwidth的区别还有使用方法，整理一下查找的内容。
晚饭吃的包子，后面六点半绕着所走了一圈，用时大约半个小时。回到实验室，和孟宇明聊了一会，然后看了一小会故宫修理文物的纪录片。后面在看最优化的第一第二次课程的课件，并且把作业完成了一下，作业比较简单，不难。

### 2016-10-10
理解概念，理解含义。
明白一个概念具体含义，非常重要，确保自己能够准确描述这个概念。

上午把最优化第二次课的ppt看了看，后面在看最优化的课本，下午也在看最优化的课本，开始看单纯形法的具体计算，研一的时候算法课学过，但是没有懂，这次好像懂了一些。晚上吃的煎饼，吃完照例绕着所遛了一圈，回到所里发现我的书包好像不见了，仔细回想了一下，应该是早上吃饭落在食堂了，但是去食堂看得时候，一楼的员工已经下班了，明天早上看一下吧。
晚上继续把单纯形的计算那些内容看了一下，如何找到初始基本可行解，如何从一个解移动到另外一个解等。

### 2016-10-11
上午董晶老师把论文修改的意见给我了，我看着，把觉得可以修改的地方又改了一下，下午在看如何解决论文的时态问题，看了一个跟时态有关的网站，好像有点远了，其实论文里面的时态没有那么多，常用的就是现在时，过去时。后面四点多去取了一下快递，回来和沈艳宇，刘瑞杰聊了一会，关于中国的货币问题等，还有一级市场二级市场等。 下午吃饭回宿舍，吃的包子加泡面，然后出去遛了一圈。回到实验室大概七点十五多一些。看了一会儿微博，然后开始看一些跟货币有关的东西，查了一下中国货币贬值有什么好处和坏处，还有中国是怎么调节汇率的。还看了一个博客，讲的是中国从明代到现代的货币制度，一个国家的兴衰跟货币的关系还是很大的。

学到了一个词语，"beggar-thy-neighbor"，指的是一个国家故意贬低（devaluate）自己的货币，增加自己的出口的优势，这样就会遏制了邻国的发展。

### 2016-10-12
上午继续在看动词时态的介绍。
以前学习的时态用英语表示如下所示，
* 一般现在时\过去时\将来时，simple present\past\future
* 现在(过去\将来)进行时，present(past\ future) continuous
* 现在（过去\将来）完成时，present(past\future) perfect
* 现在（过去\将来）完成进行时，present(past\future) perfect continuous
具体的讲述，请参考http://www.englishpage.com/verbpage/simplepresent.html

下午上最优化的课，晚上吃完饭在所周围遛了一圈，晚上没有做什么太多的事情，后面看了两集有关货币的视频。

### 2016-10-13
上午参加了一个大组会，后面跟董老师商量了一下论文的修改问题，下午去上模式识别的课程了，后面查了一下上午老师说的可以投的会议的情况，写完这个，晚饭去的"海碗居"吃的炸酱面，味道还不错，过去和回来都骑的摩拜单车，回来实验室大概八点十分。把昨天下载的《西部世界》看完了，后面看了一会摩拜单车的报道，今天腾讯等公司又给摩拜单车融资了。后面又看了一会微博。
后面学习了一下虚拟语气的用法。

### 2016-10-14
上午在看最优化的课件并且开始做题，下午继续做题，后面研究了一下使用matplotlib在坐标轴上给直线画图，并且加上一些text，给一个polygon区域上色，如何annotate一个点等等。

### 2016-10-18
15号上午在宿舍休息，下午帮忙把dsp会议的资料带过去，然后又打车回来，五点多又过去，过去也没什么事，在那边吃了个饭，然后就回来了，董晶老师把她房卡给我了，结果刚回来王伟老师又让我给他把房卡拿过去，我又过去一趟，真折腾人。
16号在会场负责一个oral session的设备，下午完了以后我就骑车回去了，去找吉吉一起吃饭，骑车从国际会议中心到北航东门，大概四十多分钟。后面发生了一些不愉快的事情，暂时不表，然后去喝了点东西，又在北航南门那边买了点小吃，那边晚上小吃摊挺多的，不错。后面又随便走了一会儿就回宿舍休息了。
17号仍然负责oral session的设置，下午完了以后没回去，拿着设备到晚宴那边以备不时之需，结果没用到，后面在那边吃了个饭，然后和其他同学一起打车回实验室。
18号仍旧，不过只到下午三点多就结束了，下午的session几乎没有人听了，只剩下一些讲者了。完了以后就一起打车回去了，我感觉困的不行就回宿舍了。在宿舍吃了点东西，玩了一会而电脑，从七点多开始休息，

### 2016-10-19
上午来实验室，看了一会儿微博，后面开始总结前面使用matplotlib画图的程序用到的东西，下午去上最优化的课了，晚上和实验室师兄师弟去吃饭，后面去北航那边找了一辆刚发布的那个mobike lite自行车，骑了一下，感觉还不错，从北航那边一直骑到了颐和园那边，大概骑到了九点四十多，后面坐车从西苑站坐到海淀黄庄，然后走回实验室的。

### 2016-10-20
上午在实验室继续整理matplotlib画图相关的东西，下午去上模式识别的课程，没怎么听懂，晚上停电了，和程文龙去北航遛了一圈，回来大概九点钟左右，上了一会儿网，看了一会电子书，继续开始整理matplotlib画图的技巧。

### 2016-10-21
前几天谷歌deep mind在nature发了一篇文章，讲的是他们利用dnc(differentiable neural computers) 解决一些现有的neural networks单独无法解决的问题，这种新的结构包含一个controller，还有external memory，controller可以向memory写入以及读取信息，controller可以接收input(可以理解为问题)，然后从memory获取知识，回答问题(也就是给出output)。


deepmind利用这种网络架构，解决了一些以前的网络解决不了的问题，譬如从graph中推理得到问题的答案(作者在文中给的例子是遍历两个地铁中的节点之间的部分，找到地铁图上两个节点之间最短距离。)
Deepmind 在2015年2月还发表了一篇关于深度强化学习的文章，把deep neural network与reinforcement learning结合起来，应用在一些游戏上面，经过一段时间的训练，得到的网络在很多游戏上的表现超过人类专业选手。在训练的时候，网络的输入只有游戏画面的像素值以及相应的得分，经过训练，网络能够明白什么时候该用哪个键，并且还能够知道每一步的value是多少。

上午整理matplotlib画图的东西，看了一下以前看过的一个matplotlib的教程。下午看了看deepmind的一些技术的介绍，以及相关的，如人类的memory如何形成，晚上下雨，本来想去北航那边吃饭，作罢，去知春里地铁那边吃了一个拉面，好贵，味道还凑活。回来又看了一会儿matplotlib的东西，晚上去打球了。

### 2016-10-23
22号上午十点多起床，吃完饭回到实验室，看了一下住的地方，这个花费了不少时间，最后选了一个觉得还行的，但是后面发现其实也不是那么好。大概一点左右从宿舍出发去南站接鹤鸣，然后一起坐地铁去住的地方，晚上一起去吃了个「小吊梨汤」，算是为生日庆祝吧。今天上午起床晚，起来随便吃了点，然后中午和鹤鸣一起坐地铁到北京北站，乘坐s2线，到八达岭长城。大约三点开始爬，我们爬的是南段，南段总共有七个城楼，然后就不能再爬了，用时并不长，不到一个小时，然后就返回了。差点没赶上回北京的s2线，如果错过下午五点三十三的火车，只能等到晚上七点多或者坐公交回去了。
大约六点四十多我们在清华园站下的，然后去北航外面的小摊上买了些吃的，当作晚餐，然后把鹤鸣送上地铁，我就回实验室了。
在实验室，看了看微博，没有看书。。。

### 2016-10-24
今天在忙着把写的论文从cvpr的格式转为iclr的格式，遇到了一个问题，iclr2017的指导里面说paper的reference应该按照字母表顺序排列，但是并未详细说明怎么个按字母表顺序排放法，而且给的pdf里面reference的风格和往年也不一样，我以为是我搞错了，所以一直想要把论文的reference部分显示搞得和去年一样，上午搞了一会，没弄出来，下午又看了一会儿，各种尝试，还是不对，最后发现使用2016年的bst文件，可以生成和往年的论文一样风格的reference，但是如果换成iclr2017的模板，就不行了。下午一直在研究这个，也没搞出来，但是稍微有点明白问题可能在哪里了，后面实在是弄的烦了，看了一会儿微博。
五点四十出去吃晚饭，不想到所里吃，就步行去北航那边了，在那边买了个肉夹馍，又吃了一个煎饼，煎饼味道一般。吃完东西，回到实验室，继续研究这个reference问题。借着前面的基础，使用linux里面的diff程序对iclr2016和iclr2017的style文件以及bst文件进行比较，终于明白了为什么reference显示与往年不同了，原来今年的bst文件和往年不同，有一些小的修改，因此reference的风格发生了变化，不再是往年的那种姓在前，名在后，中间加上逗号的方式了。

晚上搜索了一下跟参考文献相关的一些LaTeX的知识，譬如bst文件的用处，bibtex与biblatex区别，带有bib的tex文件如何编译等问题。

### 2016-10-25

今天继续修改iclr2017的论文，把原来的格式程iclr2017的格式，同时把论文的一些结构进行了稍微的调整，一些文字部分被删掉或者移动到appendix部分，同时一些图的位置进行了重排(由于iclr是单栏格式)，另外解决了一些编译时候遇到的稀奇古怪的错误问题。
到了吃晚饭的时候，基本把这个东西搞定了，晚饭去北航那边吃，发现今天那些小吃摊竟然没有营业，应该是被城管们赶走了，我还专门在小吃摊经常营业的周围转了一圈，还是没有发现，于是只好到一家店里吃了一份小面，价格真贵，16元一碗。吃完回到实验室，看了一会儿微博，大约八点半。然后把选课表打印了一下，又花费了一二十分钟。
后面开始看最优化的内容，发现这次的作业不太会做。

### 2016-10-26
上午在看最优化的讲义，然后完成老师布置的作业，下午去上最优化的课程了。晚上吃饭去北航那边，结果那些小摊还没有开张，只好去一家面馆吃了一份很贵的炒刀削，后面又吃了一份卷饼，晚上在看最优化的内容，主要是primal和dual问题，以及complementary slackness等。

### 2016-10-27
昨天上午开DIF的小组会，下午去上模式识别的课程了，老师讲的真无聊，丝毫不能让人提起兴趣，都是一些无聊的推导之类的。晚上回宿舍吃的饭，然后在宿舍睡了一会儿，大概九点钟来的实验室，又把论文改了一会儿。

### 2016-10-28
今天把iclr的论文发给了王老师，董老师，然后我自己也又看了看论文还有什么问题。下午王老师简单跟我讨论了一下论文的小问题，譬如图表的颜色，线型等，我针对性地修改了一下。后面研究了一下，如何对表格的宽度进行调整，结果发现这个问题并不简单，没有搞定。晚上和曹惠丰，刘瑞杰一起吃了个饭，好多年没见了。曹惠丰还是给人一种盛气凌人的感觉，说话也很冲，虽然看起来还是比较有礼貌的，我们一起聊了聊，然后就回去了。后面又回实验室研究了一下表格调节宽度的问题，仍然没有解决。

### 2016-10-30
昨天上午在宿舍休息，然后看了一会儿《雷震传》，下午又休息了一会，前出去买了点吃的。然后看了两集高晓松讲关于清明上河图的节目，洗了个澡，然后到实验室。不过没有看什么跟学习有关的东西，看了看经济方面的东西，把前面在微博上收藏的一个关于信用货币派生的文章看了一下，然后下载了上面推荐的两本书，又跟刘瑞杰聊了聊，然后就差不多到回去的时间了。

周日下午两点多到实验室，周日晚上在做最优化的习题，没做完。

### 2016-10-31
上午在做最优化的习题，差不多做完了。下午来实验室，曹原生加我微信，聊了一会，他现在在广州番禺区的一个工厂里面干活。两点左右王伟老师把文章修改的一些意见给我了，我根据他的意思，把文章改了改，晚饭去西格玛公寓那边吃的小面，还碰到李康了。晚上回来继续修改论文。

## 2016 年 11 月
### 2016-11-01
昨天晚上彭勃师兄也把他看了我的论文以后的一些意见给我了，今天上午和下午就根据他的意见以及自己的想法，对论文又进行了改动，并且改正了一些错误的拼写。晚上大概六点多回宿舍吃了点东西，然后又上了会网，大概八点回到实验室。后面又把论文按照董老师返回的意见修改了一下，最后又全篇检查了一下，确定没有大的错误。

### 2016-11-02
上午又把论文从头到尾检查了一下，改正了一些读起来不通顺的地方，然后下午来到实验室把论文提交到iclr上了，不知道结果如何。下午去上最优化的课了，晚上吃饭去的宿舍那边的食堂，回到实验室，晚上在看《红太阳》，看到了不到十点钟，后面看了两个小时高华讲的关于毛为什么要发动文革。他讲的确实很有意思，引用的资料也多，不错的讲座。

### 2016-11-03
上午董老师叫我下午她办公室，又稍微讨论了一下论文修改，她说我写的论文句子有的用的单词不是很平实，可能会让人读不懂，另外我把一个图的两条线去掉了，和董老师解释了一下为什么去掉那两条线。后面到位置上又稍微修改了一下，重新提交了一次，下午去上模式识别的课了，不过并没有听太多东西，感觉这课程就是一个鸡肋，老师上课全在讲那些乱七八糟的公式方法，让人在云里雾里，这样的课有什么用呢。下午六点回宿舍吃了点东西，然后看了会视频，顺便洗了个澡，大约快八点返回实验室。然后主要是把前面积攒的一些关于表格摆放的LaTeX指令整理了一下。

### 2016-11-04
上午打算把谷歌的关于Inception net的文章看一下，结果没看完，十点多程文龙让我帮他看一个LaTeX编译数学公式中出现的问题，我就帮他处理了一下，他那个公式用的是equation环境，手动分行来实现多行公式的对齐，我跟他说可以使用align环境，帮他找了一个例子。
下午我也学习了一下LaTeX里面输入数学公式的一些知识，以前学过，今天算是又复习了一下。后面继续看GoogLeNet那篇文章，GoogLeNet与前面很多人提出的网络结构都不一样，使用的并不是一个分支的网络，而是在某些地方先分叉再汇聚的形式，看的时候对这个到底是怎么实现的不是很清楚，在网上找了一下用Caffe实现的网络的prototxt看了一下，才大概明白了实现的过程，它的分支相当于使用不同大小的卷积操作，或者pooling操作，同时必须严格限定使用的的卷积核或者pooling的大小，保证各个分支输出的feature map只是channel数量不同，但是单个feature map的大小是一样的，得到各个分支的输出以后，然后再concatenate起来形成总的feature maps。
在看这个网络的实现的时候发现了Caffe卷积与pooling操作的一个不同，就是卷积与pooling的时候，其输出大小的计算并不是遵循同样的规则，因此如果其他设置相同，卷积与pooling输出的feature map大小也是不一样的。以前用的是VGG网络，比较简单，没有注意到这个问题。（update 20171004，卷积采用的向下取整计算输出大小，但是 pooling 使用的是向上取整计算输出大小。）
晚饭在所里吃的，吃完晚饭，和鹤鸣聊了一会，然后大约七点又看了一会GoogLeNet的文章，把剩下的部分看完了，然后晚上去打球了。晚上打完球看了一个电影，《老无所依》，并没有看得太懂。

**[论文阅读] Going deeper with convolutions**   
这篇文章是谷歌2014夺得ILSVRC 冠军的网络，主要讲述了一种不同于以前的深度神经网络设计范式的新的网络架构，该架构最明显的特征在于使用了分支-聚合的这种结构，而不同于以前的那种一个分支走到底的架构。同时训练的时候也在网络的某些中间位置引出一些分支，得到分类结果，然后误差反传，和最末端的输出反传的误差一起来监督网络的权重更新。

另外关于谷歌的Inception 网络的发展， 从Inception v1一直到Inception v4，这个博客有简单的介绍。
这个博客是谷歌自己的博客对自家网络的介绍。

### 2016-11-05
上午休息，大概十点半起床，看了一会新闻，然后骑车去找吉吉，和他一起吃了个饭，去的是一家新疆餐馆，我吃的炒面片。吃完又聊了一会儿，然后去沃尔玛买了点东西。然后回所里大概三点多，感觉有点困，趴在位子上休息了一下，起来又把昨天看的关于Caffe的卷积与pooling实现的不同总结了一下。
晚饭回宿舍吃的，饼子加泡面，借了顾杰的洗衣卡，然后把好久没洗的床单和毛毯一起洗了一下。然后回来实验室，把提交到ICLR的文章放到了arxiv上面，刚开始放错了，不是放的最新版本，后面又整了一下，结果图像的path没有设置对，编译不通过，后面想起来是这个问题，在tex文件里面改了一下就编译通过了。后面又写了一下昨天和今天的日志。然后又做了一会最优化的作业，没做完。

### 2016-11-06
周日大概一点多来实验室，把最优化的作业做了一下，一下午没做完，晚饭回宿舍吃的，后面晚上把最优化的作业做完，开始做模式识别的作业，发现不怎么会做，都不知道各个东西是什么意思，只好先看一会儿书，然后再做，把一些推导也看了一下，特别是关于向量矩阵求导的东西，不熟悉，半天没搞出来。

### 2016-11-07
今天主要是写qdf（quadratic discriminant funciton）的那个程序，先要在uci上找到一个分类的数据库，这个东西就很纠结，这个上面有很多数据库，而且每个都有一大串的描述，让人不知道选哪个比较好。昨天下载了一个分类的数据库，发现这个库的特征好多事类别特征，譬如男，女。下载下来，这个库是xls，所以用xlrd这个库读取了文件的书库，然后对这个数据库的特征进行了预处理，这个就耗费了好长时间，下午开始把那个qdf的实现写了出来，一直到下午快吃饭的时候才搞定，结果发现写出来的程序没什么卵用，求出来的协方差矩阵的行列式不是极度接近零，就是小于0，因此按照qdf的方法，没法计算某个样本属于某个类的概率，一直搞到了快七点还没搞定。
晚饭买的热干面，回宿舍吃的，然后看了会美剧，顾杰也回来洗澡了，等他洗完，我也洗了个澡，大约九点回的实验室。
回来以后，想着怎么解决这个协方差矩阵行列式无法计算的问题，后面想是不是数据的问题，找了半天又找了另外一个数据库，后面又想干脆先做下一个方法吧，于是又开始看书，看那个linear discriminant function的推导。直到晚上十一点多回去。

### 2016-11-08
继续写模式识别的作业，完成了前面四个实验，第五个实验还没有做。

### 2016-11-09
上午写了一下实验报告，下午去上课了，晚上查找资料，搞清楚了Parzen窗到底如何工作的，然后开始实现，做完实验以后开始写报告，一直写到了凌晨一点多，终于写完了，把报告以及运行程序等都邮件发给了课代表。

### 2016-11-10
上午开大组会，开完会查了一下写模式识别报告中遇到的一些问题，下午上模式识别的课。

### 2016-11-11
今天继续查找一些写报告中遇到的不太懂怎么用的LaTeX命令，譬如cleveref这个库里面的\cref，以及如何设置这个库，使得对方程的引用符合自己的要求。下午又查了一下XeLaTeX的一些知识，然后对以前自己总结的XeLaTeX编译中文的模板进行了小小的修改，但是出现了问题，后面经过不断测试才发现问题的根源。下午五点多出发去北京南站，晚上七点的火车。到了天津站打了一辆uber，大约八点钟到鹤鸣住的地方。

### 2016-11-13
周六吃完早饭，和鹤鸣一起尝试着做了一下枣糕，做出来以后，发现味道还行，不是很甜，而且没有外面卖的那么蓬松，颜色也没有那么深。中午吃的炒白菜，喝的疙瘩汤。下午稍微休息了一会，然后五点多出去买了点菜，面条，还有枣。晚饭我和鹤鸣一起做的炸酱面，第一次做，发现味道还不错，配菜用的黄瓜还有萝卜。吃完晚饭，鹤鸣在做菜盒子，我在这边准备第二次做枣糕，这次总结第一次的经验教训，还放了牛奶，放了红糖，量也比第一次要多，结果最后烤出来还是感觉不是很好，有点湿，也没有发起来，泡打粉可能量不够？也有可能烤箱的温度不过，烤的时间有点短，不过味道还是挺好的。

周日早上鹤鸣就去开会了，我一个人在房间里，睡觉睡到了十点多，起来热了一个菜盒子，发现不太熟，将就着吃了。鹤鸣回来的比较晚，我就先去买了点面条，黄瓜，把做面条的菜都先切好了，她回来以后我们一起又做了一次炸酱面，这次感觉味道更接近于在外面吃的炸酱面的味道。吃完饭休息了一下，就坐车回北京了。回到北京，去民大西路那边吃了一个小面，感觉那边吃饭的地方也就那样，没有第一次去的时候感觉那么好，印象打了折扣。吃完饭骑摩拜单车回来的，很方便。

### 2016-11-14
今天主要是把前面查的cleveref这个库的使用方法总结了一下，然后后面对如何使用hyperref这个库非常有兴趣，去查了一下如何更改链接的显示样式以及颜色，如何只更改TOC部分的链接颜色，最后对这些内容进行了总结。查了一下如何用LaTeX做出可以点击跳转到相应网站的网址链接，并且总结了一下。
下午六点多回宿舍，吃晚饭，热干面加包子，然后看了一集《西部世界》，这集里面发现原来那个黑人工程师Bernard也是机器人，是那个创始人老头做的。看完洗了个澡，回到实验室，大概八点多。继续整理相关内容，研究了一下如何让title能够在单独一页居中显示，从这个问题又引申出了\clearpage与\newpage的问题。
整理了一下周五下午遇到的问题，以及如何解决，把跟TeX相关的logo如何打印出来也整理了一下，后面又看了一会儿XeLaTeX的开发，以及LaTeX的历程等内容，大概十一点半回宿舍。

### 2016-11-15
上午一开始看了一会儿关于版本控制（VCS）系统的介绍，发现这个东西比我naive的办法要好，一个tex文件的变化过程可以完全用版本控制搞定，不用自己手动建立一个个文件夹，保存不同的修改版本，这样太麻烦了，打算学习一下版本控制有关的内容，下载了一个tortoiseSVN。
(2016.12.02更新)
tortoiseSVN的repository可以存放在本地，也可以自己设置一个远程的repository，通过网址访问，版本控制系统的优点就是让你能大幅度修改文件不用担心恢复问题。

上午在看关于xeCJK更多的内容，了解了更多的背景知识，发现xeCJK的开发者原来都是中国人，最初的开发者是南开大学的教授。
下午看了一下tex.sx上的一个关于如何在提问时候做一个minimum working example的meta帖子，总之原则就是能不要的就不要，跟所提的问题无关的package，以及package的选项，可以去掉就去掉，尽量精简，防止无用的东西干扰对问题本质的探求。这个帖子的一个comment提到了另外一个非常著名的博文，名字叫“What Have You Tried？”(简写为WHYT)，在这个博文里面，作者给出了如何提问才能得到别人回答的建议，我觉得写得非常好。这篇博文后面也很火，在stackoverflow的网站上被大量使用，可能都有点滥用了，所以有一段时间，如果有人在comment里面仅仅贴上这个博文网址，comment会被删掉。
晚上回宿舍吃的，热干面加包子，大约七点回到实验室。晚上把最优化的作业写了一下，一直打算用LaTeX写的，没有行动，这次最终决定用LaTeX写了，可能也是受了上周用LaTeX写模式识别作业的鼓励吧。边看老师的课件边写，中间对什么是正定矩阵有点疑惑，稍微查了一下，大约十一点半完成了作业，耗时四个小时左右。

### 2016-11-16
上午继续看latex相关的一些知识，譬如如何设置页码，latex文档的page layout，下午去上最优化的课程，回来帮程文龙整了一下他的tex文件。晚上回宿舍吃的热干面，洗了个澡，大约七点四十回到实验室。后面在看跟texlive相关的东西，譬如如何更新texlive，是否需要删除旧版等，在六维上下载了texlive2016版本，安装了一下。后面又了解了一下tex的一些东西。

### 2016-11-17
上午看了一下昨天找的一些latex的东西，比较杂，重点看了一下documented latex的含义，以及什么是literate programming，明白了dtx文件的由来，以及为什么dtx既可以编译生成sty文件，又可以生成文档。后面又看了一下MWE的一些介绍帖子，以及latex编译文件的log输出的含义等。
下午回实验室，结果看到班长消息说要办新的学生证，要用一寸照片，结果又跑回宿舍取了一张，填完新的学生证，去上模式识别，今天讲的ensemble learning。上完课，回宿舍吃了点东西，今天还是热干面加饼子，又买了根鸡肉肠。吃晚饭，看了一会儿电影，然后去理发，回到实验室的时间大概是七点半多一些。后面在看如何解决underfull \hbox的问题，发现这个东西好像还真的不简单，没有搜到能解决我的问题的答案。

### 2016-11-18
今天王伟老师组织了一个研讨会，要求小组的人去听，上午还有下午一大部分时间都在听这个（很无聊，都不知道在干吗），回来又看了一会LaTeX相关的东西，晚上去打羽毛球了。然后回宿舍。

### 2016-11-20
周六，上午在宿舍休息，大概睡到十点多，起来以后洗漱，然后去找鹤鸣，她来北京开个小会。早上起来不知怎么有点背疼，心情不好。到了鹤鸣那里大概十二点半，等她出来然后一起去吃了个面，重庆小面，味道还不错。吃完饭，没地方去，就决定去雍和宫溜达一下，进去发现没什么可看的，逛了一下就出来了。然后在雍和宫门口等了一下，鹤鸣师弟把我的鼠标带了过来（来的时候带了鼠标，因鹤鸣说要用）。不知道去哪，以前收藏了一家长沙米粉的店，所以就带她去吃米粉了，那家味道还不错，吃完饭就送她去火车站坐火车，差点没赶上，背疼加上赶时间，对她说话不温柔了，当时看她都要哭了，我也感觉很难受，不想那样。
晚上回到实验室，又看了一会LaTeX相关的，继续解决遗留问题。
周日上午一直在宿舍休息，下午大概两点多起来，去吃饭，到实验室大概三点多，继续看LaTeX相关的东西，晚饭回宿舍吃的，吃完饭，看了一集讲朝鲜战争战俘的纪录片。回到实验室，继续看LaTeX相关的东西，不断缩小。

### 2016-11-21
上午乱七八糟的忙，感觉心慌慌的，本来跟董老师发邮件说要找她讨论一下工作，结果董老师回邮件说她去台湾开会了，让我先跟王伟老师讨论一下。后面下载了一个chrome浏览器，打算废弃360，转向chrome浏览器。设置了一下gmail的邮箱，把两个邮箱合并在一起了，这里花了不少的时间。
这些东西都值得浪费时间吗？有时候我也困惑，这些小事耗费了不少的时间，我们究竟应该如何分配自己的时间呢？有时候觉得这些都不用管了，但是总觉得不去总结，只顾前行，反而会丢掉很多。
可能需要有个取舍吧。

上午还看了一下正定矩阵与半正定矩阵判定等东西，但没有细看，心慌慌的，总是赶着做事情。下午来实验室，开始做最优化的习题，跟王老师约了一下，四点钟开始谈了一个多小时，说说可以做什么，大约五点十几说完，老师建议可以做枪支检索或者那个图像谱系的工作。晚上回宿舍吃的，热干面加烧饼，然后又看了以及韩战俘路纪录片。接着洗了个澡，回到实验室，七点半多一些，然后开始做最优化的习题，前面都比较顺利，就是最后一题，好像做错了，等到明天再看吧。

### 2016-11-22
上午在做昨天的那道最优化的习题，做了一上午，计算太复杂了，求导，求根，我还专门写了个程序来处理这个问题，结果做到了吃饭的时候也没搞定，下午来继续看这个，突然发现原来是一个东西求错了，结果导致后面都算错了，一个晚上加一个早上的时间啊，细心啊。下午把那个作业做完了，然后看了一下生成的文档，发现文档的标题部分太低了，距离文档的顶端的距离过大，就查了一下如何提升文档的标题的办法。然后还把文档中的表格的绘制采用booktabs库，不再使用自带的表格制作。然后又查了一下如何单独设置表格每列第一个元素的对齐方式。后面又查了一下如何给某一段文本着色，突出显示的问题，看了看xcolor库的\colorbox与\textcolor命令的使用，发现\colorbox命令有一些缺陷，又发现了soul库提供的\hl命令适用于标记文本，在网上查了一下，并且学习了一下这些命令的使用。
在看\hl命令的时候，发现有些博文自定义命令，从而实现了用各种颜色标记文本的功能，于是对\newcommand命令如何工作感到非常好奇，又查了一下这个命令是如何工作的，并且总结了一下。

### 2016-11-23
上午总结了一下LaTeX里面如何做出水平的实线，以及水平的虚线(来自dashrule库的\hdashrule命令)，学习了一下TeX里面\leaders，\cleaders，\xleaders这三个命令的区别与联系。
下午去上最优化的课程了，回来以后在看如何调整文档为两栏，发现调整为两栏以后，自己做的标题不能横跨两栏，就查了一下如何把一部分文本横跨两栏。完成这个以后，发现在默认的文档页面排版下，有的公式太长，超出了一栏的大小，跑到了另外一栏，很不美观，于是又查了一下如何减小公式的字体，这个比较棘手，接连查了好几个地方，都没找到合适的答案，后面才找到了解决办法。七点多回宿舍吃了点东西，然后看了会视频，洗了个澡，大约九点多一些来到实验室。

### 2016-11-24
上午先把昨天查的在LaTeX中改变数学公式字体的方法总结了一下，然后看了一下tensorflow，caffe，mxnet等对facenet的实现，稍微扫了一下。到底该focus到哪个工具呢，现在有点动摇，或许哪个都可以吧，只要学好了就行。
下午去上模式识别课，由向世明老师讲神经网络，大部分时间花费在bp推导，以及后面的RBM的讲解，老师说RBM很有用，希望大家能够学习一下。下午回宿舍吃的东西，大约七点来实验室。

**[论文阅读]Reducing the Dimensionality of Data with Neural Networks**  
这时Hinton在2006发表在科学杂志上的文章，讲的是利用RBM做deep autoencoder来对数据进行非线性降维，在几个数据集上，效果要好于PCA以及其他的非线性降维方法。

### 2016-11-25
昨天一直思考神经网络的优化问题，查了一些资料，写了一点东西，晚上去打球了。

### 2016-11-26
上午休息到十点多，中午和吉吉一起去吃刀削面了，下午回实验室继续看优化方面的东西，比以前理解的更深一些了，晚上回宿舍吃的吉吉给的八宝辣子，味道不错。大约七点五十多到实验室，继续看了一会儿优化方面的东西，line search等。后面和刘瑞杰聊了一会，又看了一些关于中国经济的数据文章，明年不容乐观。

### 2016-11-28
周日睡到十二点了，起来吃了个饭，到实验室继续写那个神经网络优化的总结，没写完。昨天周一，继续写那个内容，下午去找了一下董老师，谈了一下下一步的方向问题。上午遇到了一个问题，各个地方对sgd with momentum定义不一样，看了半天，后面自己手动推导了一下，发现其实是一样的，虚惊一场。晚上继续写这个总结，差不多写完了。

### 2016-11-29
上午继续润色了一下那个总结，下午把找的一个关于SGD的博文看了一下，后面关于SGD的改进部分，没有细看，只明白大致含义。晚上把最优化的作业做了一下。

### 2016-11-30
上午在看昨天reviewer给出的意见，以及reviewer给出的应该引用的论文，我大致看了一下。下午去上最优化的课了，回来稍微看了一下python如何画piecewise function，晚饭在所里吃的，然后回宿舍洗了个澡，心情很不好，去北航那边找吉吉聊了一下，一起去护国寺小吃吃了点东西，然后又去肯德基坐了会，喝了点东西。大约十点半回到宿舍。

## 2016 年 12 月
### 2016-12-01
CNN训练的时候，输出图像的大小是否必须要一样？如果网络是全卷积的，那么这个要求就不是必须了，并且如果是全卷积，中间或者最后必然存在一个aggregate的过程，加在中间，就类似与R-MAC或者sppnet，如果是加在最后，就类似于全卷积网络那种了。

### 2016-12-02
今天为了回复reviewer的意见，看了一篇reviewer要求看的论文呢，论文很长，得到的结果也很好，可以说是目前最好的。上午下午加晚上一点时间才看完，晚上去打球了。

### 2016-12-04
周六上午在宿舍休息，十一点多起来，十二点多到实验室，开始做模式识别的作业3，下午把数据库什么的都下载了一下，晚上写了一会儿代码，画那个散点图，学了半天。周六晚上还看了一会儿中国大物理什么的，还有中国的经济之类。
周日上午睡觉了，下午来实验室继续写代码，实现fisher lda方法，发现自己的实现老有问题，跟别人的实验不一样，结果发现原来问题出在numpy的argsort上面，argsort默认是按照元素从小到大的顺序输出对应的index的，把这个改了以后就没有问题了。周日晚上又看了一会儿微博，感觉气氛不妙。到底是不是真的呢，不能像猪一样，思考非常重要。

### 2016-12-05
写模式识别的实验代码，遇到了一些问题，有的矩阵是奇异的，因此不能求逆，很讨厌，把逆都改成了pseudo inverse，前面小数据库的实验还有一点没搞完。

### 2016-12-06
写模式识别的实验代码，把前面小数据库的实验都给搞定了，然后写对应的文档，把自己前面写的表格推倒重新画了一个更好的，花费了一点时间。上午十一点多左右去董老师办公室讨论了一下给reviewer的回复，董老师说我写的有的措辞不是很polite，另外reviewer的问题有的没有回答。下午开始研究在OLHWDB上做实验，这个数据库提供的文件太破烦，竟然是什么mpf文件，研究了一下怎么读取这个文件，花费了不少时间，到了下午六七点才把这个问题搞定。会国科大食堂吃了点东西，回来感觉有点困，趴在桌子上休息了一会才感觉好一些。上网查了一下，怎么使用kmeans with prototype做分类任务。然后实现了一下，在OLHWDB上做实验，结果数据量太大，实验结果半天出不来，太坑爹啊。

### 2016-12-07
上午研究了一下那个K-means classification怎么实现的，然后借助sklearn的一些库完成了分类器，然后测试了一下，发现实现应该没有问题，中午回宿舍休息了一下。那个OLHWDB1.1所有样本的实验根本跑不动，另外自己实现的Linear Discriminant Function效率太低，把它改成了sklearn库里面的实现，速度立马提升了几十倍，但是K-means classification好像没有现成的实现，因此速度还是不行。所以最后只好折中，只用了前150类做实验。跑实验的时候，看了一会如何衡量python代码运行时间的介绍。跑完这个实验以后，开始写报告的剩下的部分，下午六点多快七点的时候把这个写完了，然后回宿舍吃了点东西，洗了个澡，八点多快九点回到实验室。又看了一会knn实现等东西，大概十一点二十回的宿舍。

### 2016-12-08
上午又看了一下做模式识别作业遗留的问题，下午看了一个网上的关于如何做表格的教程(booktabs)，学习了一下，后面开大组会。晚饭和程文龙，黄文振在所里吃的，晚上把回复给reviewer的东西又看了一下，然后回复了两个reviewer，第三个回复到一半，王老师和我聊了一会，我把回复给第三个reviewer的撤销了，等王老师看完了以后再修改一下，可能还要再做一些实验。讨论到大概十点，然后我去看了一个电影，《血战钢锯岭》，战争太残酷了。

### 2016-12-09
我的一个问题是太陷入technical的问题，推迟或者忽视了理论或者科研上的问题，并且有的时候太过于追本溯源，但是由于某些问题本身就十分庞大，一时半会难以搞清楚，所以十分不好。
周五在看关于python 的view以及indexing的一些东西。

### 2016-12-11
周六上午在宿舍休息，十点多起床，然后去找吉吉，一起去西直门那边吃饭，吃晚饭又去牛街清真寺那边，到了才发现那里也是稀松平常，没有什么值得看得东西。稍微在那逛了一会，就走了，坐地铁去三里屯那边，结果还没走几步路，这事逼又说腿疼，走不动，去咖啡馆坐了一会儿，然后出来骑车去三里屯逛了一下，没什么可看的，然后漫无目的汽车走到了亮马桥那边，到华谊兄弟的一个大楼里面坐了一会儿。到饭点了，于是一起去东吴面馆吃饭，这个面馆是在网上搜到了，发现味道也凑活，我吃的是素浇面，18元，另外加青菜，两元，总共20元。吃完饭休息了一会，往回走，吉吉还回去取他的自行车，我直接坐十号线到知春里，下车回实验室。看了一个电影《硫磺岛的来信》。看完以后，又看了一会儿python indexing方面的东西，十一点半回宿舍。

周日上午在休息，中午一点左右来实验室，刚开始看了一会儿新闻，微博之类的，看到大西洋周刊有一篇关于中国的文章，说的是中国正在往后走（The great leap backward），以后会怎么样呢？后面在看关于python程序如何测定运行时间（cProfile，timeit等），如何优化python程序的博文，晚上回国科大食堂吃了个饭。回来继续看相关内容，感觉有点困，精神不太好。看了一个 numba 加速 python 程序运行的教程，我试了一下，但是发现使用 numba 时候反而速度更慢了，不知道什么原因。

### 2016-12-12
对于使用triplet network训练模型，然后在oxford5k数据库做检索的看法。
什么是重要的，什么是不重要的，end-to-end learning 那篇文章是使用 landmark 数据库 fine-tune 了一个 triplet network，然后利用训练好的网络在 Oxford5k 上做检索，取得了不错的结果。我以前的想法一直是 Oxford5k 数据库太小了，怎么训练呢？没办法训练，但是训练不一定是非要拿该数据库的图片，可以是和该数据库相似的图片啊，这篇论文的作者聪明之处就在于使用 landmark 数据集训练triplet network，从而极大提升了 CNN 在 Oxford，Paris 等上面的效果，几乎搞得别人没什么可做的了。但是为什么一定要用和Oxford5k相似的数据库来 fine-tune 呢？如果一个网络能够很好地辨别相似与不同，这和网络实在什么数据库训练的，应该关系不大吧？譬如人的大脑，人有很多东西没有见过，但是我们能够快速判断两个 instance 是不是相似，而不用管我们到底认不认识，这个东西跟我们以前见到的什么有多相似，这些都不是判断相似时候要考虑的。我们要考虑的是物体的形状，细节等，我们并不在意这个东西到底是什么。从这些来看，神经网络还是远远逊于人类，它必须见过某些东西，才能做出判断，人类只需要见过一些东西，对于没见过的，也能做出判断，譬如相似或者不相似。

今天主要在挑选枪支那个数据库，并且了解了一下枪支基本的构成，发现挑选起来太费时间了，有的图像下载时候出现问题，还有一些是灰度图，这些图像都需要去掉。

### 2016-12-13
今天看了一篇论文，CNN Image retrieval Learn from BoW，晚上做了一下 PPT，开小组会讲。

### 2016-12-14
上午小组会，讲ppt，先是彭勃师兄讲，然后是我，感觉讲的太水了，不是很流畅，而且有时候不知道怎么传达意思。后面讲到第二篇的时候，董老师说我讲的太细了，太过于技术性，不太适合在小组会上讲，然后就没往下讲了。一晚上做的PPT就这么草草结束了 (到底该讲什么？他妈的也不说，你说该讲什么)。
中午和师兄师弟一起吃饭，然后回实验室，看着答案把最优化的作业给做了。下午去上最优化的课，感觉非常困，没有精神，也没听进去课，晚上回宿舍休息了一下，结果也没睡着，看来还是得晚上早点睡才行，晚上睡觉效率是最好的。起来洗了个澡，大约八点多回到实验室，搜索了一下 triple loss 的推导，以及网上有的一些实现，试着去理解了一下caffe的代码，发现好像并不是那么难理解，虽然自己现在可能还写不出来。看完那个caffe的实现，才回宿舍，大约十二点多一些。

### 2016-12-15
早上一起来就看到美联储加息的消息了，这是一个大新闻，然后马上就看到了一些反应，中国的债券市场崩盘了。微博上各个大V都在发表自己的看法，我对这个并不是很懂，和刘瑞杰聊了一下，对期货，债券有了更多了解，感觉这个真的是没有硝烟的战争，利用杠杆可以赚比自己的本金多得多的钱，当然风险也非常大。
中午回宿舍休息了一下，结果没睡着，脑子一直静不下来，各种嘈杂。下午来实验室，又看了一会triplet 相关的东西，再理解一下那个loss到底是如何反传的，也看了一些美联储加息的东西，后面又看了一下 mxnet 的对 deep learning framework 的介绍，imperative 和 symbolic programming 的区别等，没有完全看懂。看完这个回宿舍吃东西，今天买了三个包子，泡了一包泡面，感觉味道不错。在宿舍和顾杰聊了一会 CNN 的东西，然后八点多来实验室，做了一下 python 的一个编程挑战，结果没搞定。后面又看了一下以前写的一些笔记，思考如何才能真正创新，做出好的结果。

晚上收到了iclr论文的review，意见是论文过时了，并且一些句子在现在的背景来看，并不正确，原文用的是“misleading“，在这个领域看来还是要快，否则做的东西都成了过时的了。这个文章是一个教训，我必须从中学习到东西。我应该抽时间专门看一下reviewer的评论，平心静气分析，总结教训以及有可能的经验。

### 2016-12-16
今天在写处理 google-gun 的代码，先把损坏的还有格式不一样的处理一下，还有灰度图像，发现并没有想象的那么简单。晚上去打球了，打完球洗了个澡，又回来写了一会儿代码才把代码写完。

### 2016-12-17
首先如何确定图像是有问题的，这个就需要小心，有的损坏的图像使用windows自带的看图程序还可以打开，有的是用那个看图程序不能打开，这两种图像引起的exception是不同的，前面写代码的时候没有注意到，所以昨天程序运行到中途，遇到那种根本没有存储下来的图片就崩溃了。
另外就是本来我以为图像的shape就两种，一种是3维，一种是二维，结果今天发现有一部分图像在读取的时候，shape既不是3维也不是2维，因此程序发出了警告。出现这种情况，今天仔细研究了一下，发现有一部分图片shape出现这种问题，可能是skimage的本身的问题（高版本的skimage出现了这个问题，但是程文龙的低版本的skiamge没有这个问题，输出的shape是正常的）；还有一部分图片，后缀是jpg，但是竟然shape是4维的，一开始没想通这到底是什么图片，以为是什么3D图片，后面经彭勃师兄提醒，我突然意识到这可能是动态图片，用浏览器打开，果然是动态的，所以应该是错标成jpg后缀的gif动图。
今天上午休息，下午两点多来实验室，解决了昨天程序出现的一些错误，晚饭回宿舍吃的饼子，跟鹤鸣聊了一会，鹤鸣质疑我为什么老看那种民主自由之类的书籍，我很生气，但我没有发作，还解释了一通我也看其他书籍，我觉得她在这方面太保守或者不追求，我不喜欢她这样。后面又洗了两件衣服。
回到实验室，继续做处理图像的东西，同时也稍微总结了一下一些遇到的问题。

### 2016-12-18
下午来到实验室，继续昨天的代码，晚饭回宿舍吃的，洗了个澡，八点左右回实验室，开始做大组会的报告Presentation，好久没有使用beamer，都不是很熟了，又看了一下以前的一些东西，熟悉了一下才开始做，没写多少。

### 2016-12-19
上午和下午继续写大组会的presentation，晚上回宿舍吃的，热干面，回到实验室，对ppt稍微再修改了一些，然后解决了一下beamer写ppt过程中遇到的一些问题。大概十一点多一些回宿舍。
晚上在宿舍，把自己最近的消费总结了一下，发现自己已经很久没去食堂吃过早餐了，每天早餐都是饼子鸡蛋或者饼子香肠，至少有二十天了。感叹时间的流逝，另外觉得自己的生命就这么快速地流逝了，我每天都做了什么呢？是否是在机械地像驴一样拉着磨在转呢，不管目标和方向。

### 2016-12-20
昨天上午听了南加州大学一个教授的报告，讲的很好，很有想法，下午看了一会儿图像处理方面的东西，然后谭老师他名下的学生开了一个会，宣布他要去香港工作了，可能以后和大家见面的时间更少了。晚上回宿舍吃饭，然后洗了个澡，回实验室看了看最优化的内容，看了一下那个无明确阶段的最短路径问题的解法，函数空间迭代法和策略空间迭代法。

### 2016-12-21
今天上午来，把最优化的作业做了，后面做到使用Dijstra算法生成图的最小生成树的时候，不会搞，很沮丧，玛德，还是对这些东西不熟。
下午看了一下reinforcement learning的介绍，李飞飞学生Karpathy写的，没有完全看懂，大概明白怎么一回事。
晚饭回宿舍吃的，然后看了一会周恩来的往事，在自己的笔记本上装了一个texlive，浪费了点时间，大约快八点回到实验室。帮鹤鸣翻译了个文章的摘要，搞到了快十点钟才做完。后面又把报告稍微修改了一下。

### 2016-12-22
上午老师们要过一遍大家的ppt，我的ppt做的不太好，老师说我的背景介绍太简单了，并且方法讲的太细了，总之需要修改。有时候我也不知道到底怎么样才是可以的，到底怎么样呢？
中午和顾杰吃了点东西就往东方梅地亚中心赶，我们要参加在那里举行的一席，听了很多人的演讲，建筑师，摄影师，主持人，音乐人，艺术家等，了解了一些名词，譬如路上观察学，从王久良的演讲中了解到了中国目前存在的巨大污染，为了所谓的发展，环境被肆意破坏，这些发展到底幸福了谁的生活？
还有贾行家的演讲，对于东北广大下岗人员的过去以及下岗以后的生活有详细的描述，社会在不断的发展，总有人被抛在后面，这难道真的是他们的错误吗？还有袁硕，国家博物馆的讲解员，讲解了人类的祖先，智人。还有好多人.....
大概晚上十点中听完了演讲，和顾杰一起回去，到实验室拿了我的书包，还有大组会报告的ppt。

### 2016-12-23
开大组会，看了一些师兄师姐还有同级的做的工作，感觉他们做的东西好多，我做的东西好像工作量不够多，感觉很惭愧。
晚上在宿舍修改ppt，发现真他妈不简单，做一个图都要耗费好久的时间，到底是工具的原因还是本来做起来就不简单呢?做了一晚上也没做完，修修改改的。

### 2016-12-24
继续开大组会，吃完晚饭，赶紧回去继续修改ppt，然后练习了一下演讲的内容，我在公共场合演讲还是不熟练，有时候不知道怎么表达，这个还是得继续锻炼。晚上稍微睡的早了一些，一整晚感觉都没睡着的样子，可能是明天要讲报告吧。

### 2016-12-25
继续开大组会，今天上午是我们小组的报告，我上去讲的时候，还是有一点紧张，不过还好，后面听说我时间超了，看来对时间的把握还是不行。后面讲感想的时候，感觉自己嘴太笨了，不知道说啥，干巴巴的，如何讲话才能有吸引力呢。
中午吃完饭，大家坐大巴车回所里，我回宿舍休息了一会儿，这几天感觉总是不舒服，心情不好，没睡好，脑子也是一团浆糊。
睡到了六点多，然后起来看了一会各种消息，又在宿舍呆了一会，本来打算晚上就不去实验室了，后面觉得还是应该去实验室，不能这么放松。大概八点多到实验室，没做什么具体的工作，鹤鸣说帮我联系了一个也是搞学术的叔叔，让我跟他聊聊，结果也没聊几句。
看了看一个手机里面关于货币的视频，把最后一集看完了。有时候我也在想，我了解这些东西到底有用吗，我是不是太急于占有东西了，我有没有真正理解里面要讲的东西，花费的时间是否值得？感觉我们还是要真正能够从看过的东西中学习一些东西，而不是就那么看过就行了，问问自己是否理解书中或者视频中的概念，自己能否用清楚的话来讲述学到的东西，确保花费的时间是值得的。然后就回宿舍了。
(有的东西影响是慢慢积累的，不是一下子就能完全掌握，不能太过急躁，当然也应该认真去理解看过学过的东西，要不然耗费那么多时间有什么意义呢？)


### 2016-12-26
今天主要是把以前写的日志拿出来全部看了一遍，一个感觉，我花了好多时间在那些跟现在的研究无关的事情上，这个时间要缩短，本来研究时间就是非常稀缺的。另外我养成了晚睡晚起的习惯，周末很多时间都在睡觉中度过了，浪费了很多时间，另外还是要按照自己的内心生活，不要拘泥于太多的东西，我有时候太拘束于别人的眼光，因此会觉得拘束，自己觉得开心快乐才会有效率。
进步总是一点点产生的，阅读，写代码，一点点进步，持续努力，不要岔道，我前半年岔道太多了，总是迷茫，看得论文数量也不是很多，需要加强。
在迷茫的时候，还是应该冷静下来仔细思考自己的前途，不能灰心，灰心有什么用呢，不能解决任何问题啊，人啊，你当自助。

### 2016-12-27
今天在看图像匹配相关的python代码，解决了运行程序中遇到的一点小问题，上午和下午的一段时间都在看这个，觉得图像分类识别还是挺难的，因此物体变化太多了，如果我们的方法太rigid，那么物体稍微变化很大，那么我们的方法就失效了。因此我们的方法还是要能encode物体本质的东西，计算机视觉里面有个invariance，今天对这个词有了更深的理解，如果要想取得很好的分类效果，那么我们的算法必须是能够提取物体invariant的特征。
试了一些网上的代码，发现图像匹配的时候还是会有很多的点被错误匹配，精确度不是很高，特别是像枪支这种非常光滑的东西，错误匹配的点也比较多，也有可能是我对SIFT特征不太熟悉，anyway，如果要使用自动筛选数据的方法，必须要认真研究一下SIFT特征，还有affine transform等。
下午四点左右去vgg的主页上看了一下他们发的一些文章，发现他们发了好多文章啊，nips，cvpr，iccv，bmvc等，看了一下那个spatial transformer 的介绍视频，后面发现neural codes的作者之一在vgg当过博后，看来都是有一定关系的。
晚上回宿舍吃了点东西，洗了个澡，然后把头发理了一下，大约八点多一些回到实验室，然后开始看最优化的作业，把ford-fulkerson算法解决最大流的算法理解了一下，然后做了一下那道习题。

### 2016-12-28
今天上午在实验室看那个最小费用流的东西，玛德，看不懂，下午回到实验室也在看那个，发现涉及的东西太多了，暂时无法理解，涉及到对偶问题，还有前面的图论的一些东西，最优化后面的这些东西我都不怎么懂了，没好好学习。最后还是抄了答案，蛋疼，然后把作业交了。
后面王伟老师叫我下午谈了一下下一步的方向问题，copy-detection，或者枪支检索，都可以做，但是需要行动，不能老是这么干耗着，没进步不行。
晚上回宿舍吃东西，热干面加两个包子，然后看了一会微博上的消息，豆瓣的一个影评功能因为发布了国产电影的一些负面评论而被迫下线了，无语。大约八点到实验室，无心看书，又浏览了一会微博网页，看到了一篇foregin policy的文章，看了一下，后面又看了一下flz的一个演讲。后面和鹤鸣打了一个电话，大概这么多。最近总感觉很困，想睡觉，睡眠不足。

### 2016-10-29
今天上午和下午在看最优化动态规划那里，把那两个题目搞定了，下午还和书怀，瑞杰聊了一下，约定晚上吃饭。书怀这次来北京是办签证，要去土耳其出差了，大概下午五点四十从实验室出发，六点多到约定的地方(日昌)，等了一会，瑞杰也到了，一起吃了个饭，聊了聊。
吃完饭又去帮书怀找了个住的地方，在那里又聊了聊，他一直在玩游戏，我和瑞杰有一搭没一搭的又聊了一会，书怀昨天谈到了县里的一些情况，我觉得挺新奇的。平陆县的贫困县的帽子被摘掉了，这意味着国家的补贴没有了，县里每年的财政收入只有一亿多人民币，现在有点捉襟见肘，工资都快发不出去了，最近严查交通违章，逮住就罚款，不扣分，搞一点创收。

### 2016-12-30
今天开始复习最优化的内容，开始从线性规划开始复习，为了节省时间，中午吃完饭直接回实验室开始看东西，下午又一阵，大概三点多，感觉特别困，喝了点东西才感觉好了一些。下午五点半出发去天津，买票晚了，只买到了无座的动车。七点多一点的动车，候车的时候发了一条朋友圈，把几年看过的书分享了出去，真正回复的人寥寥，本来我加的人也不太多。
到了天津，打了个滴滴到鹤鸣住的地方。鹤鸣有点咳嗽，晚上一直喝水，上厕所，加上被子小，总担心我把被子都给卷走了，一整晚都没睡好。

### 2016-12-31
16年最后一天，上午起床吃了早餐，收拾了一下，就快十一点了，本来说买一点东西，做一下午餐，结果鹤鸣同门打电话让她过去，她们中午和老师一起吃饭，我自己一个人懒的做，就在街上点了一份饺子。吃完回去，看了一会微博，又看了一次李敖在北大的演讲，感觉他讲的真不错。很有条理并且很有趣。他谈到了自由主义，什么是自由主义？他认为自由主义有两个部分，一个是反求诸己，就是打破自己身上的枷锁，解放自己的思想；另外一个就是个人如何与国家打交道，他批评了五种个人与国家相处的消极态度，认为应该有智慧的追求自由。
这次没有看完，太困了，在床上睡着了，起来以后又看了看微博，等着鹤鸣吃饭回来，她大概四点钟才回来。下午我们一起去超市买了点东西，我做的晚饭，本来打算做豌豆面，没有买到豌豆，所以后面做了炸酱面，好久不做，忘记步骤了。吃完饭，我开始看书，鹤鸣洗了澡，早早睡觉了。我看书看到十一点多。

## 2017 年 1 月
### 2017-01-01
上午九点多起床，吃了早饭，又在房间稍事休息，因为鹤鸣的同学叫她去聚餐，我也跟着同去。去的是天大附近的一个叫"正阳春"的烤鸭店，吃完饭大概两点左右，我们陪她同学到了宿舍那边，因为晚上还要坐车，就告别了。坐公交回到住的地方，我看了一会儿李敖在复旦的演讲，感觉没有北大演讲那么精彩。后面我们把东西收拾了一下，鹤鸣嫌我不帮她整理，生气了，大约六点钟打了滴滴去车站。
坐的是七点十分从天津到北京的普通车，好久不坐普通车了，车上人特别多，很热，有点烟味，不是很舒服，到了廊坊有好多人下车了，才好了一点。九点多到了北京站，我配鹤鸣又去买了点小吃，送她进了候车大厅，我就离开了，直接回了宿舍。

### 2017-01-02
昨天晚上看了一会儿《sense 8》的圣诞特辑，接近一点钟的时候睡觉的，感觉晚上一直在微微出汗，很不舒服，没有睡好，今天定的闹钟是九点多起来的，后面太困了，一直睡到了十一点多。起来洗漱完了，看了一会儿微博，然后去吃饭，到实验室大概两点左右。下午在看最优化的考试内容，复习了一下前面的知识。下午六点多接近七点回宿舍吃了点东西，顺便把《sense8》圣诞特辑余下的部分看完了，然后把没洗的衣服和袜子洗了一下。到实验室，看了看李敖对天安门事件的看法，查了一下他的生平，他写过一本小说叫做《北京法源寺》，下载来稍微看了一下，应该是不错的。

### 2017-01-04
三号继续复习最优化的内容，把非线性规划那一部分内容稍微看了一下，重点看了一下计算部分，没有深究理论，四号上午开小组会，我都没怎么听，一直在担心下午的考试，开完小组会，吃完午饭，回到实验室继续复习了一下最优化的内容。看到群里有人上传了去年考试的题，发现都不太会做，心里有点慌张。下午两点半开始考试，有两道题是关于线性规划的，其实并不是，解答还是需要用到运输问题的知识，可是我没有看那里，因此没有计算出最后的答案。
考完试感觉很无聊，我在想学了一学期的最优化，到底有什么收获呢？好像就是学了一些计算的公式，很多背后的东西并没有理解，那么我们学习那些有用吗？并没有太大的卵用，考完试估计就快忘了，于是觉得很没有意思。当然其实还是学到了一些东西的，但是相比于付出的时间，我仍然觉得不值得，到底哪里出了问题呢？一方面，我还是受以前的教育毒害太深，总是想记住结论，不想看具体的推理过程，不想看证明，满足于会做题；另外，并没有投入太多的时间在这上面，仅仅是为了完成作业草草看一下课件；而且，老师选择的教材也有问题，这是国内教材的通病，令人厌恶的教材。
晚饭在所里吃的，吃完觉得很不爽，回宿舍洗了个澡，洗完澡又在宿舍休息了一下，八点多到实验室，一直想写一个关于「尊严」的文字，所以决定写点东西，和段鹏飞聊了一会，她抱怨了一下银行转帐24小时才能到帐的事情。后面开始写，发现自己好像写的东西太干巴巴了，没有一点文采，这个能力还是要锻炼。

### 2017-01-05
今天上午到实验室发现彭勃师兄给我前面写的cnn优化的文章提了两个typo，我就修改了一下，但我发现其实自己对softmax loss并没有太多的了解，于是上网找了一下相关的介绍，找了stanford 的cs231n的讲义，上午以及下午一段时间都在看这个，同时也稍微看了一下cross-entropy loss的含义，下午五点多看了一会儿微博，后面六点二十多回宿舍吃了点东西，看了一会高晓松的节目，高晓松宣布那是最后一期节目，说是因为一些事情的影响，以及自己想要休息等原因。7点四十多回到实验室，爸爸打了一个电话，鹤鸣也打了一个电话，后面回来更新了一篇微信公众号文章，然后后面又把斯坦福那个介绍svm loss以及softmax loss的文章看了一遍，加深理解。

### 2017-01-06
今天打算把那个spatial transformer network的那篇文章看一下，上午和洁平聊了一下，他还在天津，在研究贵金属期货，投资方面的东西，他对未来的形势比较乐观，觉得经济会越来越好。下午看那篇论文，每完全看懂它具体怎么搞的，又去网上找了一下实现代码，没细看。后面想了解一下python affine tranform的实现，就找了一下代码，大概运行了一下。五点多一些，我们这一届的一起去吃饭，去五道口那边，吃完饭一起去ktv唱歌，大约十一点十分唱完，然后回宿舍。

### 2017-01-07
今天上午大概十一点起床，昨天睡觉，早上尼玛张磊杰一直踢床，可能是我打呼噜了，踢了好几次，把我摇晃醒了，所以就起床了。十二点多和吉吉一起去西直门那边「南京大排档」吃饭，吃完饭，在那边又找了地方坐了一会儿，然后坐地铁回去，去沃尔玛买了点东西，然后吃了点东西，最后我回宿舍，他也回去了。回到实验室，不想看书，看了张赞波的《天降》，然后回宿舍吃了点东西，和段鹏飞，卫昕聊了一会，然后回到实验室继续和段鹏飞聊了一会，然后给妈妈和鹤鸣各打了一个电话，鹤鸣遇到了一个问题，复制txt到word方面的问题，发现并不是很好解决，搞了半天最后还是不是很完美。

### 2017-01-08
work hard, think hard, and play hard.
全力以赴，思考解决问题方法而不是忧虑，忧虑没有作用。

上午在宿舍休息，起床以后，看了一会儿微博，给吉吉打了个电话，让他过来拿电脑，他的电脑放在家里了，昨天他跟我说想用我的电脑写一下课程报告，我让他今天上午来取，结果上午他也没来，可能是睡觉了。看了一会微博，洗漱了一下，本来想去食堂吃饭，后面想还得等吉吉过来取电脑，出去万一他过来找不到我还得等着，所以就点了一份外卖。刚开始吃饭，他就来了，过了一会我吃完饭了，我们一起出去，我回实验室，他回学校。到了实验室，也没看什么书，感觉有点看不进去，不知道该做点啥，明明有很多事情要做，但是又不知该做什么。看了一会儿微博，晚饭回宿舍吃的，不是很饿，买了点水果，吃完东西，洗了一下衣服，洗了个澡，然后八点多回实验室。
把那篇spatial transformer看完了，刚开始看这个文章的时候，完全是有点懵，这个文章其实比较偏图像处理，核心的部分就是如何根据affine transformation参数，从输入图像采样得到输出图像。看完以后，不太清楚输出图像的每个点是如何由输入图像得到的，不明白输出图像的尺寸该如何确定，后面仔细思考了一下这个问题，同时使用opencv实验了不同大小的输出图像尺寸，发现输出图像的大小必须要大于一定的值，才能看到「真正的输出图像」，否则就是一片黑的背景。
这意味着输出图像的大小有一个最小值，有图像的部分相对于其他部分的位置其实是固定的，就像很大一块画布，图像在某个位置，然后以左上为原点，不同的输出size，相当于切出来不同大小的输出图像，如果你尺寸太小，就切不到真正的图像区域，只切到了黑色的背景，尺寸逐渐增大，切到的图像区域也越来越大。达到一定输出尺寸以后，再增大输出尺寸就没有意义了，因为增加其余部分也是黑色的背景了。

### 2017-01-09

#### affine transformation的整个过程
所谓affine transformation，就是使用一定的变换，把输入图像上的点映射到输出图像上的点，通俗来说就是把原图像上的坐标映射到输出图像坐标，这两个对应坐标位置的强度值是一样的(对于彩色图像，三个通道的值分别相同)，假如现在已经得到输入到输出的affine transformation 矩阵，那么这样我们就能根据这个变换，得到输出图像。
但是上面的过程有点小问题，如果按照affine transformation正向推导，因为输入图像上的一个坐标对应输出图像上一个坐标，但是可能覆盖不全，也就是输入图像的坐标通过变换，无法完全覆盖输出图像上的坐标，当然可以暴力解决，如果输出图像上某点不对应输入图像上的坐标，那么给该点值直接置零。也可以反着来，求出affine transformation的反变换，假设是从输出图像到输入图像映射，这样的话，当我们interate through输出图像上每个坐标，就能找到对应的输入图像上的坐标点了，实际上，找到的输入图像上的坐标并不一定存在，可能坐标中出现了负值，这时可以给输出图像上该坐标赋值一个预先设定的值，譬如0.
上述说明，存在一个实际的问题，因为图像上的点是离散的，不是连续的，所以找到的对应点的坐标一般都是小数，但是图像上的坐标都是整数，如何找到这个小数坐标对应的强度值（这个过程其实就是spatial transformer里面讲到的sampling过程）？最朴素的想法就是找出离这个小数坐标最近的点，把该点的强度值作为这个小数坐标对应的强度值；更进一步的想法是，使用双线性插值(bilinear interpolation)，把图像强度的变化看成线性变化函数，在两个方向插值，可以求出该小数坐标处的图像值。使用bilinear interpolation得到的结果，比使用最邻近方法得到的结果边缘更光滑一些，视觉效果更好。
下图是使用最邻近方法得到的边缘，可以看到有很多锯齿(zig-zag)


参考
1. bilinear interpolation
http://supercomputingblog.com/graphics/coding-bilinear-interpolation/
2. affine transformation以及inverse affine transformation
http://negativeprobability.blogspot.com/2011/11/affine-transformations-and-their.html
3. http://homepages.inf.ed.ac.uk/rbf/HIPR2/affine.htm

**[论文阅读]spatial transformer networks** 
这篇论文最重要的东西就是提出了spatial transformer 这个模块，利用这个模块，直接学习仿射变换参数，对图像进行显式的「纠正」，从而获得对旋转，缩放等操作具有不变特性的特征，实验证明，这种方式比max-pooling，能够提供更强的不变性表达。
这个module的第一部分是localization网络，用来回归变换参数，然后接下来是grid generator，最后是sampling，生成「矫正」以后的图像，其余部分就是传统的CNN。
作者提出，stn模块可以几个并行，对图像进行处理，也可以几个串行，分别接在卷积层后面，对卷积层输出的feature map进行操作。
作者实验所用的数据集是distorted mnist，svhn，还有ucsd bird，加入了stn模块以后，在这几个库上的效果都比baseline或者以前的state-of-the-art有所提升。

今天上午和下午都在看双线性插值，仿射变换的东西，差不多明白这个到底是怎么一回事了。

### 2017-01-10
做模式识别的第五次作业，看老师讲课的课件，看论文，写程序。

### 2017-01-11
继续写模式识别作业，grf程序写了，做了在vowel和sonar数据库上的实验，mnist数据集上费了点劲，先找到了能用的图片格式的mnist数据集，然后训练了一个模型，提取了2000张图像的特征用来做grf的实验。晚上把llgc的程序也写完了，刚开始的程序按照老师课件的写法，后面发现老师的课件有问题，根据原始论文写了代码，但是发现正确率非常低，怎么调整都不行。

### 2017-01-12
今天在解决那个llgc程序运行准确率太低的问题，我用的是非迭代的策略，然后发现准确率很低，所以在网上找一些开源的实现方法，发现了github上有个开源的实现，参考了一下，换成了迭代的方法，果然准确率马上上去了，然后下午把程序改了一下，写了会报告，晚上六点多回公寓那边吃饭，回宿舍洗了个澡，八点多到实验室，看了会微博。后面把报告写完，提交了。看了一会儿matplotlib colormap 的介绍的东西，今天有点困，早点回去。

### 2017-01-13
#### 画图想法
1. 颜色是一方面，另外还可以利用线型（line style），marker
2. Main principle: maximize the data / ink ratio. In other words, minimize the visual clutter, or remove everything that is not useful to understand the data.
3. http://colorbrewer2.org/ 这个网站上各种不同的颜色使用

今天主要是把写报告中遇到的一些问题总结了一下，查了一下 matplotlib 中 colormap 的使用，想要找到合适的画线条的颜色，看了一些博客的介绍，晚上去打羽毛球了，和张老师一组，这次打的不好，基本上都是被银龙和李琦师兄两个给虐了。

### 2017-01-14
上午在宿舍休息，下午来实验室，继续看matplotlib画图的一些东西，晚上和程文龙一起去吃了刀削面，回到实验室，有点困，非常不舒服地休息了一段时间，起来继续看东西，后面突然想着如何利用已有的图片生成gif图片，这应该是一个不错的东西，然后就自己实现了一下，刚开生成的图片没有标题，并且太大了，所以后面又不断迭代代码，差不多才生成了自己比较满意的照片，觉得挺有趣的，不仅学习了matplotlib提供的colormap，并且知道了怎么使用imagemagick提供的接口来生成gif图片，不过还有些不完美的地方。晚上大约十一点多回去。

### 2017-01-15
上午在宿舍休息，下午来到实验室，继续鼓捣了一会儿生成gif的东西，把生成的图片的整个过程都在python代码里面搞定了，不再需要额外在命令行里面执行命令，实验了不同framerate的gif图片，后面看了一会儿微博，然后三点左右，看了一集纪录片《death by china》，讲的是中国制造如何消灭了美国的很多制造业，并且让很多美国工人失业。五点多我和研一宿舍其他五个人一起去吃饭，本来打算去眉州东坡吃饭，到了才发现没位置，后面换到达铖说的分米鸡，结果不适合几个人一起吃饭，又换到正8楼，云南菜，吃了以后，感觉味道不错，以后可以去再吃几次。吃晚饭那八点多回到实验，开始整理这几天看的东西，关于colormap，如何使用等等，没整理完，先暂时放一下吧，明天开始写那个模式识别的报告。

刚才看了一篇文章，评比了很多画图的软件以及编程语言，地址参见https://source.opennews.org/en-US/articles/what-i-learned-recreating-one-chart-using-24-tools/

中午还和段鹏飞讨论了一下，应不应该关心政治，她的意思是现在我们没有在某一个领域的成就，人微言轻，应该关注于自己的专业，说的也不是没有道理，跟雷震的想法有点像，但是又不一样。或许我应该多操心自己的专业，专注于自己的专业，少花点时间在所谓的政治上面，别关心这些东西？但是有时候又做不到，老想去了解，矛盾啊。

### 2017-01-18
16号开始写模式识别综合报告，17号上午也在写，下午和小组的老师同学一起去聚一下，吃完饭又一起去唱歌了，唱到了晚上七点。然后王老师请客大家一起去吃炸酱面，回来继续写报告，今天继续写报告，下午终于写完了，交了报告。

### 2017-01-19
今天在帮银龙师兄解决caffe安装过程中遇到的各种问题，同时也写了一些程序，统计建文帮忙下载的数据库图片的长宽比，因为数据库中一些图片的长宽比非常大或者非常小，对于这种图片，如果resize，必然会严重变形，应该怎么弄呢？这个还是要思考一下，看一下别的论文是怎么做的，要不要去掉这些图片。

### 2017-01-20
今天上午也在帮师兄解决caffe安装的问题，最后终于搞好了。下午来实验室，继续思考一下那个数据库怎么处理，要不要重新抓取一下呢，感觉现在抓取的好多都不行。主要有两点，一个是关键词，另外就是图像长宽比，另外可能图像的质量，尺寸，颜色等，也需要考虑一下。

### 2017-01-23
周五下午坐车去天津看鹤鸣，周六上午鹤鸣去梅江会展中心的一个年货展销会当志愿者，我在家里又睡了一会儿，中午做了点炒馍花，然后坐公交过去找鹤鸣，结果坐错了一趟车，害得我多跑了好多路，一点二十除法，三点半左右才到，坐车坐的我非常丧气，周六的天冷的要死，风呼呼的吹。
到了以后，我们一起在展销会的现场逛了逛，买了点小吃，等到五点就撤了。然后陪鹤鸣去她的医师证挂靠的一个诊所，取了她的挂靠费，然后一起坐车回去。晚上不是很饿，我做的西红柿鸡蛋汤面，很好吃。
周日上午一大早，鹤鸣又去医院了，我起来吃了点东西，然后帮她把那些要整理的pdf文件弄成word格式，就是大致能看得过去，其实里面还是有很多错误，但是也管不了那么多了，应付一下。鹤鸣说这是她们医院要接受上级重点学科检查，所以要整理这些东西，不明白为什么上级检查要把pdf弄成 word，pdf不是就是很好的格式吗？而且她们中医投稿的原件都是word，为什么不去找原件呢？她说估计很多人都毕业了，原件估计也没了，顿时感到她们学术的混乱，连发表的论文原件都不建立备份系统，当事人起码自己应该留一份吧，好歹是自己发表的论文，怎么能没有备份呢？
中午一点多快两点鹤鸣才回来，我们说好的做土豆炖肉，我把材料都准备好了，就等着她回来了，她回来了开始做菜，结果炖菜的时候去和同学说话了，菜糊了，我还是忍不住说了她几句，最后把糊了的锅底给倒掉，然后把剩下的菜又弄了一下，还好，不是很糟糕。下午吃了饭就四点多了，然后一起休息了一会，晚上去滨江道那里逛街，先吃了点东西，然后在附近的店里看了看衣服，晚上十点多回去的。

今天上午起来，鹤鸣去医院了，我收拾了一下屋子，把她的衣服甩干晾了起来，然后打车去车站回北京，下车到海淀黄庄那边吃了点东西，回实验室，结果困的不行，也没看了什么东西，四点多回宿舍，看了二十多分钟电影，然后睡了一觉，睡到了将近八点钟，到了实验室，把彭勃师兄让我看得那篇文章看了一下，我觉得有点问题的地方标了出来，然后发给了他。

### 2017-01-24
上午在宿舍休息，十点多起床，去吃了饭，然后到实验室，后面和王洪松师兄坐在休息室聊了一会儿，下午把前面搜集的关于如何保存gif的方法整理了一下，然后把唐德刚的《新中国30年》看完了，晚饭和程文龙，王洪松师兄一起去吃的刀削面，回来把以前查的一些利用python处理文件，图像的一些东西又整理了一下，九点多在休息室看了一会《红太阳》，然后又看了一会matplotlib可视化的一个教程，然后和鹤鸣说了一会。
